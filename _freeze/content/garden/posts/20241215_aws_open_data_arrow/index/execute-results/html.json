{
  "hash": "8e4207dbc40bf35fa15f01173f081945",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Looking up open datasets in AWS Marketplace using {arrow}\"\nsubtitle: Using the {arrow} package to look into and. use datasets in S3 storage\nimage: \"images/aws.jpeg\"\ndate: \"12/17/2024\"\ndraft: false\npage-layout: article\ntoc: true\ntoc_float: true\ncomments:\n  utterances:\n    repo: ngiangre/ngiangre.github.io\n---\n\n\n\n# Introduction\n\nHave you ever wanted to dive into *huge* biological datasets, do a little citizen science, or just sharpen your coding skills? [**AWS Open Data Registry**](https://aws.amazon.com/marketplace/search/results?trk=8384929b-0eb1-4af3-8996-07aa409646bc&sc_channel=el&CONTRACT_TYPE=OPEN_DATA_LICENSES&DATA_AVAILABLE_THROUGH=S3_OBJECTS&PRICING_MODEL=FREE&FULFILLMENT_OPTION_TYPE=DATA_EXCHANGE&filters=CONTRACT_TYPE%2CDATA_AVAILABLE_THROUGH%2CPRICING_MODEL%2CFULFILLMENT_OPTION_TYPE) is a treasure trove of public datasets you can access for free! Today, we'll explore the **Clinical Proteomic Tumor Analysis Consortium (CPTAC-2)** dataset. \n\nCPTAC-2 is part of a national effort to accelerate our understanding of cancer biology through proteogenomics. The datasets include RNA-Seq, miRNA quantification, and other valuable tools for cancer research. Exciting stuff, right? Let’s access and explore it using R and packages like **`{arrow}`** and **`{purrr}`**.\n\n---\n\n# Key Packages and Techniques\n\nThis post relies on a few key packages and techniques to unlock the data:\n\n- **`{arrow}`**: Enables seamless access to data stored in AWS S3 buckets and efficient handling of large datasets.\n- **`{purrr}`**: Makes iterating over data structures easy and expressive.\n- **`{stringr}`**: Provides handy tools for string manipulation.\n- **`{tibble}`**: Simplifies working with tabular data in R.\n- **`{dplyr}`**: A powerful tool for data manipulation and transformation.\n\nHere’s how we’ll use these tools to:\n1. Connect to an AWS S3 bucket and explore its structure.\n2. List and classify the available files.\n3. Load specific datasets into dataframes based on their type for analysis.\n\nBy the end, you’ll know how to apply these packages to answer key questions like:\n- What datasets are available in the CPTAC-2 bucket?\n- How can we identify and load the files we need?\n- What insights can we draw from these datasets?\n\n---\n\n# Exploring the Data\n\n## Connecting to AWS S3 Storage\n\nThe CPTAC data lives on an S3 bucket in AWS. To access it, we’ll use `arrow::s3_bucket`. The `{arrow}` package makes working with cloud storage and large datasets seamless. Let’s set up the connection:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Connect to the CPTAC-2 open data bucket on AWS\ncptac_s3 <- arrow::s3_bucket(\"s3://gdc-cptac-2-phs000892-2-open/\")\n```\n:::\n\n\n\nBoom! We now have a pipeline into the bucket, and we can start peeking at its contents.\n\n## Listing Folders and Files\n\nThe first step is to see what’s inside this giant bucket.\n\n### Listing Folders\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# List all folders in the bucket\ncptac_folders <- cptac_s3$ls()\nlength(cptac_folders)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3984\n```\n\n\n:::\n\n```{.r .cell-code}\ncptac_folders[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"00308a6b-56f8-4e51-9b4b-500ca6d32387\"\n[2] \"006fc0cd-8419-4278-887b-ee922340fd85\"\n[3] \"0088029e-05f1-461c-a30a-2d6628a7f8d2\"\n[4] \"00997ac4-8cc4-4c90-a2ab-d4a36068faf0\"\n[5] \"00d681ae-9382-4224-a8a2-d51fd4dbaa28\"\n```\n\n\n:::\n:::\n\n\n\nHere, `cptac_s3$ls()` gives us the top-level folder names in the bucket.\n\n### Listing Files in Each Folder\n\nNow that we have folders, let’s dive into them and list the files inside. We’ll use the `purrr::map_chr()` function to map over the folders and fetch the file names.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# List all files within the folders\ncptac_files <- purrr::map_chr(\n    cptac_folders,\n    ~{ cptac_s3$ls(.x) }\n)\nlength(cptac_files)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3984\n```\n\n\n:::\n\n```{.r .cell-code}\ncptac_files[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"00308a6b-56f8-4e51-9b4b-500ca6d32387/35036955-3a03-4b7a-bd55-d8bc721f99c4.htseq_counts.txt.gz\"                   \n[2] \"006fc0cd-8419-4278-887b-ee922340fd85/fcc26511-0b8b-4914-ad7e-bb97a3cd03f8.FPKM-UQ.txt.gz\"                        \n[3] \"0088029e-05f1-461c-a30a-2d6628a7f8d2/34566acf-5f1f-4b7c-859a-5c7c2c38ed8e.wxs.aliquot_ensemble_masked.maf.gz\"    \n[4] \"00997ac4-8cc4-4c90-a2ab-d4a36068faf0/4dc10240-c4ca-4b92-866b-af1542575fc8.rna_seq.augmented_star_gene_counts.tsv\"\n[5] \"00d681ae-9382-4224-a8a2-d51fd4dbaa28/c2de32e3-b9bc-49e1-9dbe-8c09b48ff637.htseq_counts.txt.gz\"                   \n```\n\n\n:::\n:::\n\n\nThis step takes each folder and retrieves the files within.\n\n## Classifying File Types\n\nLet’s get curious: what types of data are in these files? We'll extract file extensions to see what formats are available.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract file types by splitting filenames\ncptac_filetypes <- purrr::map_chr(\n    cptac_files,\n    ~{\n        (basename(.x) |> \n         stringr::str_split_fixed(pattern = \"\\\\.\", n = 2))[2]\n    }\n)\n\n# Count the occurrences of each file type\ntable(cptac_filetypes)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ncptac_filetypes\n                        FPKM-UQ.txt.gz                            FPKM.txt.gz \n                                   340                                    340 \n                   htseq_counts.txt.gz   mirnaseq.isoforms.quantification.txt \n                                   340                                    650 \n    mirnaseq.mirnas.quantification.txt rna_seq.augmented_star_gene_counts.tsv \n                                   650                                    340 \n       rna_seq.star_gene_counts.tsv.gz     wxs.aliquot_ensemble_masked.maf.gz \n                                   340                                    984 \n```\n\n\n:::\n:::\n\n\n\nHere, we:\n1. Use `basename()` to get the file name without the folder path.\n2. Split the file name at the first dot (`\\\\.`) to extract extensions.\n3. Count the file types using `table()`.\n\nThis gives us a nice summary of the types of files: **.txt.gz**, **.tsv**, and so on.\n\n---\n\n# Loading Specific Datasets\n\nNow for the fun part: let’s load and explore some actual data. We’ll define rules to read specific file types, like gene expression files and miRNA quantification data. Since this is a lot of files to structure, we'll just go through a few examples. Here’s the magic:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read in data based on file type\ncptac_s3_df_20 <- tibble::tibble(\n    cptac_folders,\n    cptac_files,\n    cptac_filetypes\n) |> \n    head(20) |> \n    dplyr::mutate(\n        df = list(NULL),\n        df = purrr::map2(cptac_files, cptac_filetypes, ~{\n            if(.y %in% c(\"htseq_counts.txt.gz\", \"FPKM-UQ.txt.gz\", \"FPKM.txt.gz\")){\n                cptac_s3$path(.x) |> \n                    arrow::read_delim_arrow(delim = \"\\t\", col_names = FALSE) |> \n                    tibble::tibble() |> \n                    dplyr::rename(ensembl_id = f0, value = f1)\n            } else if(.y %in% c(\"rna_seq.augmented_star_gene_counts.tsv\")){\n                cptac_s3$path(.x) |> \n                    arrow::read_delim_arrow(delim = \"\\t\", skip = 1) |> \n                    tibble::tibble()\n            } else if(.y %in% c(\"mirnaseq.mirnas.quantification.txt\", \"mirnaseq.isoforms.quantification.txt\")){\n                cptac_s3$path(.x) |> \n                    arrow::read_delim_arrow(delim = \"\\t\") |> \n                    tibble::tibble()\n            } else if(.y %in% c(\"wxs.aliquot_ensemble_masked.maf.gz\")){\n                cptac_s3$path(.x) |> \n                    arrow::read_delim_arrow(delim = \"\\t\", skip = 7) |> \n                    tibble::tibble()\n            }\n        })\n    )\ncptac_s3_df_20\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 4\n   cptac_folders                        cptac_files     cptac_filetypes df      \n   <chr>                                <chr>           <chr>           <list>  \n 1 00308a6b-56f8-4e51-9b4b-500ca6d32387 00308a6b-56f8-… htseq_counts.t… <tibble>\n 2 006fc0cd-8419-4278-887b-ee922340fd85 006fc0cd-8419-… FPKM-UQ.txt.gz  <tibble>\n 3 0088029e-05f1-461c-a30a-2d6628a7f8d2 0088029e-05f1-… wxs.aliquot_en… <tibble>\n 4 00997ac4-8cc4-4c90-a2ab-d4a36068faf0 00997ac4-8cc4-… rna_seq.augmen… <tibble>\n 5 00d681ae-9382-4224-a8a2-d51fd4dbaa28 00d681ae-9382-… htseq_counts.t… <tibble>\n 6 00fdd1b4-a87d-4db4-90d3-4c73ff1c9c3e 00fdd1b4-a87d-… wxs.aliquot_en… <tibble>\n 7 012a0d15-2d7d-4bab-af3f-ba3d808331c1 012a0d15-2d7d-… mirnaseq.isofo… <tibble>\n 8 01302114-2e59-4695-8ec5-93883b9e8f44 01302114-2e59-… FPKM-UQ.txt.gz  <tibble>\n 9 013e52b9-1a81-41ef-a287-71bfcfb5c5eb 013e52b9-1a81-… mirnaseq.mirna… <tibble>\n10 0144f8ae-ebd9-421f-abfd-83da589a8660 0144f8ae-ebd9-… FPKM.txt.gz     <tibble>\n11 0150be78-91fe-4628-bed9-f79c74aa31d1 0150be78-91fe-… htseq_counts.t… <tibble>\n12 015c8c0a-421f-4a58-86fb-664575786002 015c8c0a-421f-… FPKM.txt.gz     <tibble>\n13 016a2336-115d-4542-82ce-f5b4d5e08805 016a2336-115d-… rna_seq.augmen… <tibble>\n14 017d77e5-c9d9-4888-a0c5-2b27a26910c3 017d77e5-c9d9-… FPKM-UQ.txt.gz  <tibble>\n15 01886ea8-8c31-4e41-b136-731fd79e775e 01886ea8-8c31-… mirnaseq.isofo… <tibble>\n16 018f0332-4225-48f2-8ba9-6f2dad922532 018f0332-4225-… mirnaseq.isofo… <tibble>\n17 01947104-063e-4bf5-ab9e-b9797ccdfcee 01947104-063e-… mirnaseq.mirna… <tibble>\n18 01c70055-4080-49c4-8980-9e152f8b9635 01c70055-4080-… FPKM.txt.gz     <tibble>\n19 01c7a24a-ca38-4961-87bf-a91734df83cd 01c7a24a-ca38-… FPKM-UQ.txt.gz  <tibble>\n20 01cae191-097d-4df3-b599-f3709c4a95f1 01cae191-097d-… mirnaseq.mirna… <tibble>\n```\n\n\n:::\n:::\n\n\n\nHere’s what happens:\n- **File Types**: Depending on the file type (RNA-seq, miRNA, etc.), we apply different parsing rules.\n- **`arrow::read_delim_arrow()`**: Reads data efficiently from the bucket.\n- **Skipping Headers**: Some files need skipping rows before the actual data.\n\nWe now have actual dataframes loaded into the `df` column for exploration.\n\n---\n\n# Wrapping Up\n\nIn this post, we:\n1. Connected to an AWS S3 bucket to access the CPTAC-2 dataset.\n2. Explored the folder and file structure.\n3. Classified file types to understand the available data.\n4. Loaded specific datasets into R for analysis.\n\nThe CPTAC-2 dataset is a treasure trove for exploring cancer biology, and tools like `arrow` and `purrr` make accessing and analyzing such massive datasets both accessible and fun. The possibilities are endless—whether for academic research, personal projects, or learning new coding techniques.\n\nSo, go on and explore some datasets!\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}