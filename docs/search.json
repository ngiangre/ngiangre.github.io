[
  {
    "objectID": "content/cv/Nicholas_Giangreco_academic_CV.html",
    "href": "content/cv/Nicholas_Giangreco_academic_CV.html",
    "title": "Nicholas Giangreco",
    "section": "",
    "text": "Github | Linkedin | ORCID | nickg.bio | nick.giangreco@gmail.com | Date of preparation: November 1st 2020"
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_academic_CV.html#education",
    "href": "content/cv/Nicholas_Giangreco_academic_CV.html#education",
    "title": "Nicholas Giangreco",
    "section": "EDUCATION",
    "text": "EDUCATION\n\n2016 - Present\n\nPhD Candidate, Systems Biology; Columbia University, New York City, NY\nMasters of Arts (2018) and Masters of Philosophy (2019)\n\n2010 - 2014\n\nBS, Biochemistry; University of Rochester, Rochester, NY"
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_academic_CV.html#work-experience",
    "href": "content/cv/Nicholas_Giangreco_academic_CV.html#work-experience",
    "title": "Nicholas Giangreco",
    "section": "WORK EXPERIENCE",
    "text": "WORK EXPERIENCE\n\n2016 - Present\n\nSystems biology Graduate Research Assistant (Columbia University); New York, NY\nPhD advisor: Dr. Nicholas Tatonetti\n\nJune 2019 - August 2019\n\nClinical informatics intern (Regeneron Genetics Center)); Tarrytown, NY\nDeveloped database of multivariate clinical associations using incremental learning on amazon web services.\n\nJuly 2018 - September 2018\n\nComputational biology intern (Genetic Intelligence Inc.); New York, NY\nConducted independent and collaborative genomics research using NCBI APIs and amazon web services.\n\n2014-2019\n\nCancer bioinformatician (National Human Genome Research Institute); Bethesda, MD\nPost-baccalaureate trainee 2014-2016; Special volunteer 2016-2019\nInvestigated ovarian endometrioid tumorigenesis by integrating and analyzing RNASeq and DNA methylation sequencing (MBD-Seq)."
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_academic_CV.html#fellowships-and-awards",
    "href": "content/cv/Nicholas_Giangreco_academic_CV.html#fellowships-and-awards",
    "title": "Nicholas Giangreco",
    "section": "FELLOWSHIPS AND AWARDS",
    "text": "FELLOWSHIPS AND AWARDS\n\nThree-Minute Thesis 2019 finalist @ Columbia Graduate School of Arts and Sciences.\nBest contribution in methodological research at the OHDSI 2018 Symposium for Pediatric Drug Safety poster.\nColumbia Diversity Fellowship.\nDepartment of Systems Biology Merit Fellowship.\nDonald Charles Award, University of Rochester Department of Biology.\nFulbright Fellowship Alternate 2013-2014: Sweden, Molecular Modeling, “Novel Antibody-SpA Complex Modeling”.\nTravel Award to 9th Student Council and ISMB/ECCB conference 2013 Berlin, Germany."
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_academic_CV.html#publications",
    "href": "content/cv/Nicholas_Giangreco_academic_CV.html#publications",
    "title": "Nicholas Giangreco",
    "section": "PUBLICATIONS",
    "text": "PUBLICATIONS\n\nNicholas Giangreco, Jonathan Elias, and Nicholas Tatonetti. No population left behind: improving pediatric drug safety using informatics and systems biology. British Journal of Clinical Pharmacology (DOI).\nNicholas P. Giangreco, Barry Fine, Nicholas P. Tatonetti. cohorts: A Python package for clinical ’omics data management. bioarxiv\nBenjamin S Glicksberg, Boris Oskotsky, Phyllis M Thangaraj, Nicholas Giangreco, Marcus A Badgeley, Kipp W Johnson, Debajyoti Datta, Vivek A Rudrapatna, Nadav Rappoport, Mark M Shervey, Riccardo Miotto, Theodore C Goldstein, Eugenia Rutenberg, Remi Frazier, Nelson Lee, Sharat Israni, Rick Larsen, Bethany Percha, Li Li, Joel T Dudley, Nicholas P Tatonetti, Atul J Butte, PatientExploreR: an extensible application for dynamic visualization of patient clinical history from electronic health records in the OMOP common data model, Bioinformatics, , btz409, https://doi.org/10.1093/bioinformatics/btz409\nBenjamin S Glicksberg, Boris Oskotsky, Nicholas Giangreco, Phyllis M Thangaraj, Vivek Rudrapatna, Debajyoti Datta, Remi Frazier, Nelson Lee, Rick Larsen, Nicholas P Tatonetti, Atul J Butte, ROMOP: a light-weight R package for interfacing with OMOP-formatted electronic health record data, JAMIA Open, Volume 2, Issue 1, April 2019, Pages 10–14, https://doi.org/10.1093/jamiaopen/ooy059\nCastillero E., Ali Z., Akashi H., Giangreco N., Wang C., Ji R., Zhang X., Kheysin N., Park J., Hegde S., Patel S., Stein S., Cuenca C., Leung D., Homma S., Tatonetti N., Topkara V., Takeda K., Colombo P., Naka Y., Sweeny L., Schulze C., George I. Structural and Functional Cardiac Profile after Prolonged Duration of Mechanical Unloading: Potential Implications for Myocardial Recovery. American Journal of Heart and Circulation Physiology, article in press\nSarah Kim-Hellmuth, Matthias Bechheim, Benno Puetz, Pejman Mohammadi, Yohann Nedelec, Nicholas Giangreco, Jessica Becker, Vera Kaiser, Nadine Fricker, Esther Beier, Peter Boor, Stephane Castel, Markus M. Noethen, Luis B. Barreiro, Joseph K. Pickrell, Bertram Mueller-Myhsok, Tuuli Lappalainen, Johannes Schumacher, Veit Hornung. Genetic regulatory effects modified by immune activation contribute to autoimmune disease associations Nature Communications, 8 (266): 1-10.\nGiangreco N., Petrykowska H., Scott A., Margolin G., Gotea V., Cho K. R., and Elnitski L. Inactivation of Arid1a drives aberrant epigenetic traits in a mouse model of Apc/Pten defective ovarian endometrioid tumors. (in preparation)\n\nPeer-Reviewed Publications on Pubmed"
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_academic_CV.html#posters-and-software",
    "href": "content/cv/Nicholas_Giangreco_academic_CV.html#posters-and-software",
    "title": "Nicholas Giangreco",
    "section": "POSTERS AND SOFTWARE",
    "text": "POSTERS AND SOFTWARE\n\nNick Giangreco and Nicholas Tatonetti. Using precision pharmacovigilance to detect developmentally-regulated adverse drug reactions: a case study with antiepileptic drugs. poster github\nNick Giangreco and Nicholas Tatonetti. Using precision pharmacovigilance to detect and evaluate antiepileptic drug associated adverse reactions in pediatric patients. poster\nNick Giangreco and Nicholas Tatonetti. cohorts. github\nNick Giangreco. Scan2CNV. OMICSTools\nGiangreco N, Zorn E, Chen E et al. Identification of novel primary graft dysfunction biomarkers using exosome proteomics [version 1; not peer reviewed]. F1000Research 2017, 6:2080 (poster) (doi: 10.7490/f1000research.1115115.1)\nGiangreco N and Lezon T. Alternative conformation prediction of Vibrio Cholerae concentrative nucleoside transporter. F1000Posters 2013, 4:776 (poster)."
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_academic_CV.html#leadership-and-management-experience",
    "href": "content/cv/Nicholas_Giangreco_academic_CV.html#leadership-and-management-experience",
    "title": "Nicholas Giangreco",
    "section": "Leadership and Management Experience",
    "text": "Leadership and Management Experience\n\nCUIMC Data Science Club\n\nPresident 2017-\nOrganize and manage team of officers, oversee activities, manage budget, and promote outreach portfolio to support and strengthen the data science skills of biomedical scientists at CUIMC\n\nHealth Tech Assembly\n\nPresident 2019-2020\n\nManage business, medical, public health, and engineering representatives for inter-school events, panels, and conferences at Columbia.\nOrganize and plan professional/social engagement events.\nNetwork and connect with NYC-wide entrepreneurs and professionals.\n\nMedical campus representative 2018-2019\n\nGraduate Student Organization at Columbia University Irving Medical Center\n\nCo-President 2019-2020\n\nOrganize and manage team of Biomedical PhDs for social and professional activities serving hundreds of CUIMC PhD students.\n\nFinance Chair 2018-2019\n\nColumbia Graduate Council\n\nTreasurer 2019-2020\n\nEstablish budget and expense sheets and annual reports\nManage forty thousand dollar budget for Columbia inter-school activities.\n\n\nDepartment of Biomedical Informatics\n\nCo-lead weekly seminar series\nManage presentation schedule, speaker logistics and travel, and promote team coordination.\n\nDepartment of Systems Biology\n\nPoint person for Systems Biology Trainee Council\nSecured funding and launched event portfolio for trainee development\nManage monthly departmental happy hours\n\nNew York Health Artificial Intelligence Society\n\n501(c)(3) not-for-profit Cofounder and Secretary\nMeetup co-organizer 2018-\nPromote public discourse on a wide range of topics such as AI & Society, AI & Healthcare, and economic impact by AI.\nOrganize and facilitate group engagement, workshops, AI study groups, and not-for-profit organization.\nConsultant on data science and education projects and initiatives.\n\nUniversity of Rochester Alumni Undergraduate Interviewer\n\nAssess potential and suitability for undergraduate college\nInterviewer at large and small event settings"
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_academic_CV.html#mentoring-tutoring-and-writing",
    "href": "content/cv/Nicholas_Giangreco_academic_CV.html#mentoring-tutoring-and-writing",
    "title": "Nicholas Giangreco",
    "section": "MENTORING, TUTORING, and WRITING",
    "text": "MENTORING, TUTORING, and WRITING\n\nMentor and tutor for project management, R and python programming, and statistics and machine learning to high school and college students, graduates, and professionals.\n“Hack nights – Solving healthcare data-science/AI/ML problems” Introduction to cancer genomics four part series. Co-led with Matthew Eng\n\nAdventures In Hacking Healthcare Medium Publication\n\nNicholas Giangreco. “The Importance of being Open”. PHDISH January 9th 2019.\nMentoring:\n\nPayal Chandak, Undergraduate at Columbia University\n\nProvide guidance and instruction in biomedical data science and research training.\nProvided guidance and mentoring for summer 2018 research internship in the Tatonetti Lab\n\n“Drugs with sex-linked risk for adverse drug reactions”\n\n\nSMRI high school mentorship\n\nProvide guidance to high school student in biomedical data science research project\n\n\nCuriology tutor\n\nManaged and co-led science experiments with NIH fellows for middle school students in Washington D.C.\n\nCollege Bound tutor\n\nFacilitated completion of homework assignments in STEM for Washington D.C. high school students.\n\nGenetics Study Group Leader, Center for Excellence in Teaching and Learning, University of Rochester."
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_academic_CV.html#conferences-and-hackathons",
    "href": "content/cv/Nicholas_Giangreco_academic_CV.html#conferences-and-hackathons",
    "title": "Nicholas Giangreco",
    "section": "CONFERENCES AND HACKATHONS",
    "text": "CONFERENCES AND HACKATHONS\n\nElixir biohackathon\n\nCollaborated with bioinformatics team to integrate nextflow scheme and cancer mutation data (vcf files) into OMOP standard structure using ROMOPOmics.\n\nHack for NF, Children’s Tumor Foundation\n\nCo-lead web developer coordination and product development\nA FHIR-complient and primarily patient-centric profile for NF management and centralized repository for medical journey.\n\nJudge, Predictive analytics track, Columbia University COVID-19 Data Challenge\nVirtual Interoperathon 2020\n\nProject developer for personalized health record accessed with fhir-client python api\nDeveloped flask application proof-of-concept.\n\nNCBI Hackathon @ Carnegie Mellon University January 2020\n\nProject co-lead for developing and extending common data model to represent biological ’omics data for reproducible queries and analyses.\nSee original OMOPOmics and R package ROMOPOmics github repository.\n\nCSHL Biological Data Science meeting November 2018.\nOHDSI 2018 Symposium\nNCBI Hackathon @ New York Genome Center August 2018\n\nProject lead for developing data science notebooks and web application interfacing with drug safety data.\nSee SafeDrugs github repository.\n\nIntelligent Systems in Molecular Biology, July 2018\nSecond Northeast Computational Health Summit, April 2018\nAmerican Heart Association Scientific Sessions 2017, poster presentation Giangreco et al. 2017.\nNCBI Hackathon @ New York Genome Center June 2017.\nNCBI Hackathon @ NCBI March 2017.\nCSHL Biological Data Science meeting October 2016.\nJHU DaSH Hackathon September 2015.\nISMB/ECCB conference @ Berlin, Germany July 2013, poster presentation Giangreco et al. 2013."
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_academic_CV.html#talks-and-panels",
    "href": "content/cv/Nicholas_Giangreco_academic_CV.html#talks-and-panels",
    "title": "Nicholas Giangreco",
    "section": "TALKS AND PANELS",
    "text": "TALKS AND PANELS\n\n“Intro to Bioinformatics and How to Analyze Brain Tissue with Data Science”. Invited presentation at NYC Medical Research and Bioinformatics Group. November 2018. Presentation link.\nMedical Research Career Panelist, Minds Matter NYC, June 2018\nStandardized and Reproducible Analysis Enables Identification of Novel Primary Graft Dysfunction Biomarkers using Exosome Proteomics, Second NorthEast Computational Health Summit 2018, April 2018.\n“Tools, Libraries and Analyses in Biomedical Data Science”, New York Healthcare Artificial Intelligence Society, December 2017.\n“Doing Science with Big Data”, Late Night Science, Columbia University Neuroscience Outreach, December 2017.\n“AI, Life Sciences, and Big Data”, New York Healthcare Artificial Intelligence Society, August 2017. Presentation link.\nNIDDK Undergraduate Step-Up Judge, NIH, Bethesda MD, August 2015."
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_academic_CV.html#professional-memberships",
    "href": "content/cv/Nicholas_Giangreco_academic_CV.html#professional-memberships",
    "title": "Nicholas Giangreco",
    "section": "PROFESSIONAL MEMBERSHIPS",
    "text": "PROFESSIONAL MEMBERSHIPS\n\nInternational Society of Computational Biology, 2013-2014 & 2017-\nAmerican Heart Association, 2017-2018.\nAmerican Medical Informatics Association, 2017-2018."
  },
  {
    "objectID": "content/garden/projects/mccv/mccv-shiny.html",
    "href": "content/garden/projects/mccv/mccv-shiny.html",
    "title": "MCCV (Shiny for Python) App",
    "section": "",
    "text": "Interactive App for exploring Monte Carlo Cross Validation predictions from the {mccv} package using Shiny for Python.\nRead more at the GitHub site."
  },
  {
    "objectID": "content/garden/projects/mccv/mccv-simulation.html",
    "href": "content/garden/projects/mccv/mccv-simulation.html",
    "title": "MCCV for Biomarker Prediction",
    "section": "",
    "text": "The motivation for this study is to compare MCCV and traditional hypothesis testing, such as the t-test, as methods for learning outcomes from varied biomarker distributions. The work is being implemented in a collection of notebooks in the github repository. The evaluation results and presentation is being made as Reavel.js slides."
  },
  {
    "objectID": "content/garden/projects/buffalo/index.html",
    "href": "content/garden/projects/buffalo/index.html",
    "title": "Buffalo & Western New York",
    "section": "",
    "text": "library(leaflet)\ndat &lt;- data.frame()\nleaflet(data=dat) %&gt;% \n    addTiles() %&gt;% \n    addProviderTiles(provider=\"HERE\") %&gt;% \n    leaflet::setView(-78.878, 42.886, zoom = 10) %&gt;% \n  addRectangles(\n    lng1=-78.6, lat1=42.7,\n    lng2=-79, lat2=43.1,\n    fillColor = \"transparent\"\n  )\n\n\n\n\n\nMoving back to my hometown, Buffalo NY, has been a fantastic experience. Buffalo and Western New York generally speaking has been going through tremendous economic development and growth over the past decade. I wasn’t able to appreciate what the city and surrounding area had to offer until recently. As a citizen scientist, I want to explore Buffalo and WNY through data. I plan on using publicly available data, like from the Open Data Buffalo initiative, to explore, understand, and communicate about my hometown and why I love living here. Stay tuned for more on this project!\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/garden/projects/pds/pds-database.html",
    "href": "content/garden/projects/pds/pds-database.html",
    "title": "KidSIDES",
    "section": "",
    "text": "An R data package to connect with real-world drug safety signals during childhood. See the github link for details."
  },
  {
    "objectID": "content/garden/projects/nfldatadashboard/index.html",
    "href": "content/garden/projects/nfldatadashboard/index.html",
    "title": "Showcasing NFL NextGenStats",
    "section": "",
    "text": "Firs prototype - vizualization dashboard for comparing nfl players: https://nick-giangreco.shinyapps.io/nfldatadashboard/\nSecond prototype - website tabulating nfl player’s Next Gen Stats scheduled to update over the season: https://ngiangre.github.io/nflstats/website/index.html\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/garden/posts/20230625_kidsides_announcement/index.html",
    "href": "content/garden/posts/20230625_kidsides_announcement/index.html",
    "title": "Announcing the kidsides R package",
    "section": "",
    "text": "One of the main research questions during my PhD was how does the biology of childhood interact with medications taken during by children? After years of research and reading the literature my thesis became:\n\nAdverse drug reactions manifest from the interaction between drug exposure and dynamic biological processes during child growth and development.\n\nTo investigate, we generated thousands of statistical signals of the interaction between pediatric population drug reporting and the child development stage resulting in an adverse event1. For more details the reference is freely available at this reference1.The statistical model we used was a generalized additive model with this basic specification g(E(Adverse reaction)) = spline(stage, by = Drug)\nThe {kidsides} R data package makes this database more accessible by caching the SQLite database on your machine. You can read up more regarding installation at the website https://kidsides.nickg.bio. Additionally, there is an overview on the data within the database at this vignette, and a tutorial on extracting smaller, more manageable datasets in this vignette.Fair warning, R 4.0 and above is required; and the entire database is almost 1 GB\nYour main questions about {kidsides} may be what data do the tables have and what kind of graphics could I make? In this post, I want to\n\nGive a preview of all 17 tables in the SQLite database.\nShow how the strength of the hypothesized interactions depending on the class of a medication, such as cardiovascular or psychiatric drug class. Interaction investigated here: Number of reports for an adverse drug event vs. Estimated drug safety signal.\n\nI will make use of Frank Harrell’s reptools R code that will make individual tabs in this document for each table/graph below.\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(Hmisc)\nHmisc::getRs('reptools.r')\n\nThere are only 3 functions that come with {kidsides}. Once {kidsides} is installed from CRAN, you can easily cache the database with the following command:`install.packages(‘kidsides’)\n\nkidsides::download_sqlite_db()\n\nThe cache location is determined by the {tools} package. Using the other two functions in {kidsides}, you can easily connect and disconnect from the database, respectively.\nNow, onto the showcases!\n\ncon &lt;- kidsides::connect_sqlite_db()\n\n\n\n{kidsides} SQLite database table previews (first 100 rows)Drug class interactions\n\n\ntables &lt;- DBI::dbListTables(con)\n\nitems &lt;- purrr::map(tables,~{\n  DT::datatable(tbl(con,.x) %&gt;% \n                                           head(100) %&gt;% \n                                           collect(),\n                         options = list(dom = 'tf',\n                             pageLength=5,\n                             scrollX = TRUE,\n                             deferRender = TRUE,\n                             scrollY = 500,\n                             scroller = TRUE),\n                        extensions = 'Scroller')\n})\nnames(items) &lt;- tables\nmaketabs(items)\n\nadeade_nichdade_nichd_enrichmentade_nullade_null_distributionade_rawatc_raw_mapcyp_gene_expression_substrate_risk_informationdictionarydrugdrug_geneeventgenegene_expressiongripryansider\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsoc_categories &lt;- tbl(con,'event') %&gt;% \n    select(meddra_concept_name_4) %&gt;% \n    distinct() %&gt;% \n    collect() %&gt;% \n    na.omit() %&gt;% \n    pull()\nitems &lt;- purrr::map(soc_categories,~{\n    soc_events &lt;- \n        tbl(con,'event') %&gt;% \n        filter(meddra_concept_name_4==.x) %&gt;% \n        select(meddra_concept_id) %&gt;% \n        distinct() %&gt;% \n        collect() %&gt;% pull() %&gt;% na.omit()\n    soc_ades &lt;- tbl(con,'ade') %&gt;% \n        filter(meddra_concept_id %in% soc_events & \n                   gt_null_99) %&gt;% \n        select(ade) %&gt;% \n        distinct() %&gt;% \n        collect() %&gt;% pull() %&gt;% na.omit()\n    tmp &lt;- tbl(con,'ade_nichd') %&gt;% \n        filter(ade %in% soc_ades) %&gt;% \n        select(ade,nichd,gam_score_90mse,DE) %&gt;% collect()\n    eps &lt;- 0.0001\n    ades_ordered &lt;- \n        arrange(tmp,gam_score_90mse) %&gt;% \n        slice(1,.by=ade) %&gt;% pull(ade) %&gt;% factor()\n    ade_cluster_map &lt;- \n        tbl(con,'ade') %&gt;% \n        select(ade,cluster_name) %&gt;% \n        filter(ade %in% soc_ades) %&gt;% \n        collect()\n    plot_tmp &lt;- \n        tmp %&gt;% \n        left_join(ade_cluster_map,by='ade') %&gt;% \n        mutate(\n            ade = factor(ade,levels=ades_ordered),\n            nichd = factor(nichd,levels=c('term_neonatal',\n                                          'infancy','toddler','early_childhood',\n                                          'middle_childhood','early_adolescence',\n                                          'late_adolescence')),\n            signal = if_else(gam_score_90mse&gt;0,gam_score_90mse,eps))\n    plot_tmp$DE_cut &lt;- \n        cut(plot_tmp$DE,breaks = c(0,1,5,50,as.integer(max(plot_tmp$DE))),include.lowest = T)\n    pos &lt;- position_dodge2(width = 0.7)\n    p &lt;- plot_tmp %&gt;% \n        ggplot(aes(nichd,signal,group=ade)) +\n        geom_line(alpha=0.2,position = pos) + \n        geom_jitter(aes(fill=DE_cut),pch=21,size=3,position = pos) +\n        guides(fill=guide_legend(title='Number of Reports',\n                                   title.position = 'top')) +\n        scale_color_brewer(palette = 'Set1') +\n        scale_fill_viridis_d() +\n        scale_y_sqrt() +\n        labs(x=\"Number of Reports\",\n             y='Statistical Signal (lower bound)') +\n        facet_wrap(~cluster_name,ncol=2) +\n        theme_linedraw(base_size = 16) +\n        theme(\n            axis.text.x = element_text(angle=45,vjust=1,hjust=1),\n            legend.position = 'top'\n        )\n  p\n})\nnames(items) &lt;- soc_categories\nmaketabs(items)\n\nBlood and lymphatic system disordersCardiac disordersCongenital, familial and genetic disordersEar and labyrinth disordersEndocrine disordersEye disordersGastrointestinal disordersGeneral disorders and administration site conditionsHepatobiliary disordersImmune system disordersInfections and infestationsInjury, poisoning and procedural complicationsInvestigationsMetabolism and nutrition disordersMusculoskeletal and connective tissue disordersNeoplasms benign, malignant and unspecified (incl cysts and polyps)Nervous system disordersPregnancy, puerperium and perinatal conditionsProduct issuesPsychiatric disordersRenal and urinary disordersReproductive system and breast disordersRespiratory, thoracic and mediastinal disordersSkin and subcutaneous tissue disordersSocial circumstancesSurgical and medical proceduresVascular disorders\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhew, that was a lot of information! No worries, feel free to look through the {kidsides} website and the vignettes. Hopefully you will see it is easy to access and extract data from this database.\nThere are so many questions, visualizations, and analyses to be made with this data. I hope this short post provides a sneak peak into the database to wet your palette for more explorations. If you use this database in your work, I would love to hear about it!\n\nkidsides::disconnect_sqlite_db(con)\n\n\nReferences\n\n\n1. Giangreco NP, Tatonetti NP. A database of pediatric drug effects to evaluate ontogenic mechanisms from child growth and development. Med (N. Y.). 2022;3(8):579–595.e7."
  },
  {
    "objectID": "content/garden/posts/20240218_dl_book_start/index.html",
    "href": "content/garden/posts/20240218_dl_book_start/index.html",
    "title": "New learning journey: Deep Learning with R",
    "section": "",
    "text": "⚠️ Short, Technical Post Alert ⚠️\nI’m starting to read the book Deep Learning with R. I will be putting some code snippets from my reading at the below github repository. What I’ve learned so far:I’ve been meaning to read this since I had this book signed at rstudio::conf(2022)\n\nYou can use {renv} to set, record, and manage a python virtualenv.\nIt is very simple to get started with NN models using {keras}.\nYou can use {reticulate} to bring predictions from python objects into R dataframes for visualization using {ggplot2}!\n\nClick here for GitHub"
  },
  {
    "objectID": "content/garden/posts/20240101_nfldatadashboard_announcement/index.html",
    "href": "content/garden/posts/20240101_nfldatadashboard_announcement/index.html",
    "title": "A dashboard for interacting with NFL data",
    "section": "",
    "text": "Happy New Year everyone! Today’s post is brought to you by the data science hobbyist in me and a new quest.\nThis year I started a Fantasy Football team with my brother. As he explained what FF is and how it is played, I am fascinated by how one understands how a player or team performs on the field and over the season. I’m now wondering how to leverage my background in data and statistics to understand performance in the National Football League.\nMy new quest and hobby is to leverage my background to formalize how I can interact with and use data to understand NFL player performance. As a started thinking about this topic, though, I realize how complex the data is and how player or team performance is. I am not a domain expert in sports (NFL)! However, maybe my background is strong enough to pull me from my dearth of knowledge and into the light.\nThis holiday season I made {nfldatadashboard}, an R package that installs a shiny dashboard for viewing and interacting with NFL data (limited to 2023 season currently). The source is NFL Next Gen Stats, which I pulled using the R package {nflreadr}. I then used the R package {targets} for extracting and saving the datasets. Finally I used the R package {R6} to standardize both the data retrieval and data plotting in the dashboard. The dashboard was developed using the framework from the R package {golem}. There’s no testing included yet as this is a prototype and is likely to change.\nWhile building {nfldatadasdhboard}, I learned some new skills and built on others. I used the R packages {ggplot2} and {ggiraph} for plotting that includes interactivity. I used custom and standard dashboard themes using the R package {bslib}. Using objects with {R6} let me separate dashboard reactivity from functionality that lacks reactivity, as this can be a source of technical complexity.\nI hope to be building on {nfldatadashboard} as I learn from my brother (resident NFL expert) and pointers given by everyone out there reading this post. If you made it this far, thank you! And let me know your thoughts in the comments on how to make the dashboard more accessible and intuitive.\nClick here for link to Github repository\nClick here for link to live dashboard\nP.S. I want to explicitly say, I leverage many useful resources put out by the R community and the teaching/workshop material I learned over the past years (e.g. posit conf, hackathons, etc.). I am forever indebted to the R community in which I work and live in."
  },
  {
    "objectID": "content/garden/posts/20250111_training_load/index.html",
    "href": "content/garden/posts/20250111_training_load/index.html",
    "title": "Creating choices while maintaining high training volume",
    "section": "",
    "text": "I bought resistance bands this week! I joined a gym last month! I have a regular routine of doing medical pilates each week, but recently I’m wanting to complement that with strength training.\nOne thing I’m told you want to do is aim for progressive overload. The idea is applying stress to the body over time drives adaptations such as muscle growth, increased endurance, and new neural pathways (i.e. teach the brain that the body can do new stuff). I’m constantly working on new movements, but I’d like to try to start activating and grow muscles in ways I haven’t done before. To do this, increasing training volume promotes progressive overload to help me reach my goals.\nThe resistance bands I bought come in 10 pound increments. I may have to start really light and repeat movements alot in order to teach my brain a new movement and promote muscle growth. I was curious about how I can maintain or increase training volume either but repeating the movement alot or increase the weight. This had me thinking of controlling variables but changing one to see how that affects training volume. And then considering a few approaches and seeing where the training volume is similar. This calls for a little simulation!\nbut first, I am defining training volume by the product of Sets, Reps, Tempo, and Weight. There’s a lot of other variables that affect training volume, but let’s say that only these variables matter within a specific exercise. Just a note on tempo: this is comprised of the seconds it takes to perform the eccentric movement, pause at the top, and perform the concentric movement (E-P-C for short) which all is time under muscle tension.\nLet’s say we consider 1-6 sets, 5-50 reps in increments of 5, 1+1+1/2+2+2/3+3+3/3+5+3 for Tempo, and 10 to 90 in 10 pound increments\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nlibrary(ggiraph)\n\n\ntraining_volume_df &lt;- \n    expand.grid(\n        sets = 1:6,\n        reps = seq(5,50,5),\n        tempo = c(3,6,9,11),\n        weight = seq(10,90,10)\n    ) |&gt; \n    dplyr::mutate(\n        training_volume = sets*reps*tempo*weight,\n        tempo = case_when(\n            tempo==3 ~ '1/1/1',\n            tempo==6 ~ '2/2/2',\n            tempo==9 ~ '3/3/3',\n            tempo==11 ~ '3/5/3'\n        ),\n        tooltip = paste0(\n            'Sets: ',sets,'\\n',\n            'Reps: ',reps,'\\n',\n            'Tempo: ',tempo,'\\n',\n            'Weight: ',weight,'\\n',\n            'Training Volume: ',scales::comma(training_volume)\n        )\n    ) |&gt; \n    dplyr::mutate(\n        across(all_of(c('sets','reps','tempo','weight')),as.character),\n        reps = factor(reps,levels = seq(5,50,5))\n    )\ntraining_volume_df |&gt; \n    head()\n\n  sets reps tempo weight training_volume\n1    1    5 1/1/1     10             150\n2    2    5 1/1/1     10             300\n3    3    5 1/1/1     10             450\n4    4    5 1/1/1     10             600\n5    5    5 1/1/1     10             750\n6    6    5 1/1/1     10             900\n                                                           tooltip\n1 Sets: 1\\nReps: 5\\nTempo: 1/1/1\\nWeight: 10\\nTraining Volume: 150\n2 Sets: 2\\nReps: 5\\nTempo: 1/1/1\\nWeight: 10\\nTraining Volume: 300\n3 Sets: 3\\nReps: 5\\nTempo: 1/1/1\\nWeight: 10\\nTraining Volume: 450\n4 Sets: 4\\nReps: 5\\nTempo: 1/1/1\\nWeight: 10\\nTraining Volume: 600\n5 Sets: 5\\nReps: 5\\nTempo: 1/1/1\\nWeight: 10\\nTraining Volume: 750\n6 Sets: 6\\nReps: 5\\nTempo: 1/1/1\\nWeight: 10\\nTraining Volume: 900\n\n\nLet’s look at how training volume changes as only the weight changes:\n\ntmp &lt;- \n    training_volume_df |&gt; \n    dplyr::filter(\n        sets==3,reps==15,tempo=='2/2/2'\n    )\n\ng &lt;- \n    tmp |&gt; \n    ggplot(aes(weight,training_volume,group=sets)) +\n    geom_line() +\n    geom_point_interactive(aes(tooltip = tooltip)) +\n    scale_y_continuous(\n        name = 'Training Volume',\n        labels = scales::comma\n    ) +\n    theme_bw(\n        base_size = 16\n    )\n\ngirafe(ggobj = g,width_svg = 10,height_svg = 5)\n\n\n\n\n\nLinear relationship - not surprising. So before going further, I’m going to put some code into a function so we can make more of these types of graphs but with less code. We’re going to change the data filters and the basic aesthetics of the plot, but everythin else will be the same.\n\nmake_line_plot &lt;- function(g_start,thresholds = NULL,facet = NULL,base_size = 20,nrow = 1, width = 10,height = 5){\n    g &lt;- \n        g_start +\n        lapply(thresholds,function(x){\n            geom_hline(aes(yintercept=x),\n                           linetype='dashed',\n                           color='red',\n                           linewidth=2)\n        }) +\n        geom_line(linewidth=1) +\n        geom_point_interactive(aes(tooltip = tooltip),\n                               size=2) +\n        scale_color_viridis_d(option = 'D',direction = -1) +\n        scale_fill_viridis_d(option = 'D',direction = -1) +\n        scale_y_continuous(\n            name = 'Training Volume',\n            labels = scales::comma\n        ) +\n        theme_bw(\n            base_size = base_size\n        )\n    \n    if(!is.null(facet)){\n        g &lt;- \n            g +\n            facet_wrap(vars(.data[[facet]]),nrow = nrow)\n    }\n    \n    girafe(ggobj = g,width_svg = width,height_svg = height)\n}\n\nLet’s make the same graph but vary the sets and color them. Also, I’m adding a way to see what are our options to get a certain training volume.\n\ntraining_volume_df |&gt; \n    dplyr::filter(\n        reps==15,tempo=='2/2/2'\n    ) |&gt; \n    ggplot(aes(weight,training_volume,\n               group = sets,\n               color=sets,fill=sets)) |&gt; \n    make_line_plot(thresholds = 18000)\n\n\n\n\n\nThis graph shows we can hit that training volume with different sets EXCEPT 1 or 2 sets. I could hit the same volume with 3-6 sets. So at more sets I can use a lower weight. Cool.\nWhat about if keep the set the same but vary the tempo?\n\ntraining_volume_df |&gt; \n    dplyr::filter(\n        reps==15\n    ) |&gt; \n    ggplot(aes(weight,training_volume,\n               group = tempo,\n               color=tempo,fill=tempo)) |&gt; \n    make_line_plot(thresholds = 18000,facet = 'sets',\n                   width = 12,nrow=2)\n\n\n\n\n\nAt 4 sets I can use 30 pounds with very low tempo like 3/5/3 to get the volume I want whereas I’d have to do 6 sets if I only could use 20 pound weights.\nFor a realistic scenario, I think the 3/5/3 is good for me so I can activate muscles and I think I’ll stick to 3 sets. Now. I want to vary weight and reps.\n\ntraining_volume_df |&gt; \n    dplyr::filter(\n        tempo=='3/5/3',sets==3\n    ) |&gt; \n    ggplot(aes(reps,training_volume,\n               group=weight,\n               color=weight,fill=weight)) |&gt; \n    make_line_plot(thresholds = seq(1e4,1e5,length.out = 4),\n                   width = 10,height=6,base_size = 16,nrow=2)\n\n\n\n\n\nIf I wanted to hit those high training volumes, I’d have to increase to very high reps and not necessarily increase the weight so high. So if I can’t go to higher weights because stabilizing the weight is not possible, atleast I can increase the reps enough to hit the volume needed for progressive overload.\nHere’s a useful finding! If I can’t increase the weight, I can acheive the same training volume by doubling the reps.\n\ntraining_volume_df |&gt; \n    dplyr::filter(\n        tempo=='3/5/3',sets %in% 3:6,\n        weight %in% 10:50\n    ) |&gt; \n    ggplot(aes(reps,training_volume,\n               group=weight,\n               color=weight,fill=weight)) |&gt; \n    make_line_plot(thresholds = seq(1e4,1e5,length.out = 4),\n                   facet = 'sets',\n                   width = 12,height=10,base_size = 16,nrow=2)"
  },
  {
    "objectID": "content/garden/posts/20240512_dl_learning_fail/index.html",
    "href": "content/garden/posts/20240512_dl_learning_fail/index.html",
    "title": "Deep learning fail - it happens",
    "section": "",
    "text": "As I am reading through the book Deep Learning with R, I tried to apply some of the learnings but with no success. This is part of how we learn new material, so its ok! Here are some notes on my application, what happened, why it didn’t work out, and what to do next.\n\nMy applied problem\nI made a dataset from the data in the {kidsides} R package which has information on millions of self reported adverse drug events in the US population from the 1990s to 2019. The dataset had predictors on what the drug and event classes were for the drugs and adverse events in each of the reports.\nI constructed a training set to learn what characteristics could determine whether a report contained more than one drug included in a report. Basically, I wanted to learn what characteristics associated with reported. adverse drug events that involved polypharmacy.\n\n\nWhat happened\nI made a few deep neural network models that varied in the number of nodes in one dense layer, included 20% dropout of nodes (basically adding noise to the learning process), and varied in the size of samples used in the learning process. I used 40% of the data to validate the training process. In the end, I trained 6 different models.\nI monitored the training and validation loss and accuracy. The models ended up not having enough ability to learn any patterns in the data, and the models weren’t able to learn enough (no overfitting occurred).\n\n\nWhy it didn’t work out?\nAlot of reasons but here are 4:\n\nThe question was not posited correctly.\nThe dataset did not contained the relevant features.\nThere wasn’t enough data to learn meaningful patterns.\nThe model wasn’t constructed well enough to learn patterns if there were any.\n\n\n\nWhat next?\nI need to think more about the question and construct a better dataset. I think {kidsides} contains a lot of information to learn about how and when adverse drug events may occur in the US population.\nI need to construct deep learning models that have a better ability to detect patterns in the data. Trying different types of model architectures may help.\nI also could just give up and say deep learning is not well suited for this kind of data. Deep learning is fantastic at representing data and finding patterns in images, text, and other information. It may be overkill for tabular data. Most likely it is.\nIn the end, this was a good exercise for me to try my hand at and get some experience with these models. You can find the script at the Github linked below. Thanks for reading about my learning journey!\nClick here for GitHub"
  },
  {
    "objectID": "content/garden/posts/20231028_shinylive/index.html",
    "href": "content/garden/posts/20231028_shinylive/index.html",
    "title": "Shinylive - shiny apps with no server",
    "section": "",
    "text": "A Shiny for R App involves constant communication between two things: 1) the website (shiny) or basically what you see and interact with, and 2) the server that crunches data from your interactions in R. With any communication, it’s a labor of love - it takes time, effort, and things break if there isn’t communication. A Shinylive App, as opposed to a Shiny for R App, does not involve this communication between the website and server. The data crunching from your interactions occur on the website. No server is needed - no communication - no extra time, effort, and chance of breaking from no communication.\nBelow is an example of a Shinylive App. The interaction (i.e. slider) data is crunched directly on this website. No extra communication needed.\n#| standalone: true\n\nfrom shiny import *\n\napp_ui = ui.page_fluid(\n    ui.input_slider(\"n\", \"N\", 0, 100, 40),\n    ui.output_text_verbatim(\"txt\"),\n)\n\ndef server(input, output, session):\n    @output\n    @render.text\n    def txt():\n        return f\"The value of n*2 is {input.n() * 2}\"\n\napp = App(app_ui, server)"
  },
  {
    "objectID": "content/garden/posts/20230610_mccv_announcement/index.html",
    "href": "content/garden/posts/20230610_mccv_announcement/index.html",
    "title": "Announcing the mccv python package with Quarto website",
    "section": "",
    "text": "One of the research questions during my PhD was can we generate evidence before a heart transplant for proteins in blood to predict heart failure within 24 hours after the transplant? Ideally, the clinical team wanted an equation that would provide a probability of heart failure for a patient. Another requirement for this equation was that it would generalize to patients across heart clinics, such as in the US or Europe, and outperform existing clinical scores. This question was what motivated developing the algorithm Monte Carlo Cross Validation (MCCV)*.*The algorithm is not new, but in late 2016 I wasn’t familiar with an open source implementation for the question and I wanted to use this as an opportunity to learn python.\nFast forward 5 years, 2 papers were published where we used MCCV and found pre-transplant predictive evidence for plasma kallikrein (KLKB1) towards post-transplant heart failure1,2. The algorithm MCCV was written as a few python functions in scripts for both papers3,4. At the time of publishing the papers, I knew I would eventually incorporate the functions into a package to make the algorithm more widely available*. That time came after publishing the papers and after I defended my PhD thesis. Serendipitously, the software Quarto, which was announced by Posit, allowed making a website AND interchangeably write python and R code in the same document. Quarto allowed showcasing the algorithm in both programming languages (with prettier visualizations from R) along with tutorials and detailed explanations.*Also I wrote the python package for the opportunity to code in python since I mostly code in R for work.\nThe mccv python package is available on GitHub and is also shown on a website* written in Quarto. The website includes several tutorials in the navigation bar at the top of the page.*https://ngiangre.github.io/mccv/ or https://mccv.nickg.bio\nThank you for reading this post! Reply in the comments if you find the algorithm useful in your own work. I also want to give a shoutout to the Quarto team for developing a great communication tool. I highly recommend having an accompanying website for analytical software packages (luckily, this is easier for developing R packages with the {pkgdown} package])!\n\nReferences\n\n\n1. Giangreco NP, Lebreton G, Restaino S, Jane Farr M, Zorn E, Colombo PC, Patel J, Levine R, Truby L, Soni RK, Leprince P, Kobashigawa J, Tatonetti NP, Fine BM. Plasma kallikrein predicts primary graft dysfunction after heart transplant. J. Heart Lung Transplant. 2021;40(10):1199–1211.\n\n\n2. Giangreco NP, Lebreton G, Restaino S, Farr M, Zorn E, Colombo PC, Patel J, Soni RK, Leprince P, Kobashigawa J, Tatonetti NP, Fine BM. Alterations in the kallikrein-kinin system predict death after heart transplant. Sci. Rep. 2022;12(1):14167.\n\n\n3. Giangreco N. Ngiangre/clinical_klkb1_analysis: First release. 2021.\n\n\n4. Giangreco N. ngiangre/kng1_analysis: Revision code for manuscript. 2022."
  },
  {
    "objectID": "content/garden/posts/20250217_observable_learning/index.html",
    "href": "content/garden/posts/20250217_observable_learning/index.html",
    "title": "Part 1: Learning a new way to make visuals with Observable",
    "section": "",
    "text": "Introduction\nI like to think I am pretty well versed in R programming and especially using the {ggplot2} package to make visualizations. The great thing about making visualizations in R, among many, is the functional programming where I can make a reusable function that iterates over variables to create many similar plots.\nBut sometimes you just want to create one plot, and make sure it’s pretty easily interactive, is pretty fast, and can scale. Also motivated by my desire to learn a new approach, I am going to use Observable to generate a plot I would usually make in R. This will be a multi-part post since I’m pretty sure I won’t be able to do everything below all at once:\n1. Data: I will use pediatric drug safety data from the {kidsides} R package.\n2. Tables and Plots: I will then set out to create a table to show the data and highlight/interpret some syntax. Then, I will create boxplot, scatterplot, and heatmap. Along the way, I will explain the code used to create the plots. I will try to make the points interactive (hover over effect) and modify some aesthetics such as color, tooltips, and labels.\n\nDataObservable ObjectObservable Table\n\n\nIn addition to getting data from the R package, to make the data available to Observable I have to use ojs_define in order to “lift over” the data from the R environment to the Observable environment in ‘ojs’ code chunks. data then becomes an array of objects.\n\nlibrary(kidsides)\nlibrary(dplyr)\nlibrary(DBI)\ncon &lt;- kidsides::connect_sqlite_db()\ndata &lt;- \n    tbl(con,\"ade_nichd_enrichment\") |&gt; \n    collect()\n\nojs_define(data = data,small_data = head(data,5))\n\n\n\nWhat does the data look like in Observable if I just print it?\n\nsmall_data\n\n\n\n\n\n\n\n\nViewing the table is really snappy! Real fast scrolling. This vignette from Observable goes through some cool tricks with the penguins dataset.\n\nfunction sparkbar(max) {\n  return x =&gt; htl.html`&lt;div style=\"\n    background: lightblue;\n    width: ${100 * x / max}%;\n    float: right;\n    padding-right: 3px;\n    box-sizing: border-box;\n    overflow: visible;\n    display: flex;\n    justify-content: end;\"&gt;${x.toLocaleString(\"en\")}`\n}\n\nviewof selection = Inputs.table(transpose(data),{\n  sort: \"odds_ratio\",\n  reverse: true,\n  columns: [\n    \"odds_ratio\", \"atc_concept_name\", \"meddra_concept_name\", \"nichd\", \"category\"\n  ],\n  header: {\n    odds_ratio: \"Odds\", \n    atc_concept_name: \"Drug\", \n    meddra_concept_name: \"Event\",\n    nichd: \"NICHD Child Stage\",\n    category: \"Category\"\n  },\n  format: {\n    odds_ratio: d3.format(\".2f\"),\n    odds_ratio: sparkbar(d3.max(transpose(data), d =&gt; d.odds_ratio))\n  }\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInputs.table()\n\nThis is a built-in Observable Plot Inputs function. It generates an interactive table where users can sort, filter, and explore data.\n\ntranspose(data)\n\ntranspose() is a helper function from Observable that transforms the data from “wide” format to “long” format (or vice versa, depending on the structure). If data is an array of objects, transpose(data) converts it into an array of arrays, ensuring each column is properly structured for display.\n\nsort\n\nThe sort and reverse arguments do wha we expect: sort the odds_ratio column in descending order.\n\ncolumns\n\nThe columns argument allows for selecting and ordering columns for the table. The column names have to be strings.\nThis argument needs to be in square brackets.\n\nheader\n\nBut, you can set a new column name (as a string) on the right side of a : with the original column name (as a string) on the right.\nThis header argument needs to be in curly braces!\n\nformat\n\nformat allows for controlling how the data is displayed in the table.\nd3 refers to D3.js wherein Observable Plot is built on top of. Observable uses D3 for added functionality like formatting.\nsparkbar is a function that creates an inline spark bar chart. It creates this within HTML to be rendered in the table. The =&gt; in JavaScript is used for arrow functions, which provide a more concise syntax for defining functions. The function takes the max value from the odds ratio column using the arrow function. htl.html used in the function is a template literal function from the htl (Hypertext Literal) library. It safely generates HTML in Observable notebooks.\n\n\nAnnnnnd, what is really cool is selecting rows in the above table gives a totally reactive table like below:\n\nInputs.table(selection)\n\n\n\n\n\n\n\n\n\n\n\nConclusion\nThis post was short but in the next post we’ll do some plotting!"
  },
  {
    "objectID": "content/garden/posts/20220904welcome/index.html",
    "href": "content/garden/posts/20220904welcome/index.html",
    "title": "Hello, world!",
    "section": "",
    "text": "Hello! This is exciting for a couple of reasons:\n\nThis is the redesign of my original website\nThis redesigned website is made using Quarto\nThis redesigned website is now hosting my digital garden\n\n\nMy digital garden is like a virtual showcase\nIn Buffalo, I learned that there’s an annual garden walk, where people all over the city can venture through and see wonderful gardens carefully crafted and skillfully maintained by their gardeners. These gardens are open to the public and showcase plants and outdoor designs serving as inspiration and just very nice places to experience.\nSimilar to a real garden, I want to craft a digital garden. My digital garden will be carefully crafted to showcase new and old projects, both matured content and content in development. What makes this digital garden deviate from my profile on Github is that 1) it is organized as a mixture of long-term, project work and short-term, stand-alone posts, and 2) it is meant as sort of an “official” landing page from my personal website.\nI acknowledge how my digital garden will deviate from a digital knowledge tree or mind map, as described in this article about the ethos. However, I really like the idea of thinking-out-loud and sharing knowledge and resources openly. So here we are.\n\n\nI will make an effort to work on my digital garden like a gardener tends to their garden in the backyard\nCurrently, alot of the work in my garden is projects from my time as a graduate student. I’m very proud of the work I contributed to and the open access work. After my time as a graduate student, there’s still so muc to explore and to work on! Obviously I won’t have a ton of time to devote to personal projects; besides work and family, I also need to catch up to my partner on the Marvel universe on Disney+…But when I can I will be definitely working more on growing existing work and knowledge in an effort to think-out-loud and develop as a scientist.\n\n\nHow Quarto is fantastic software for making your digital garden\nI wanted to give my original website a face-lift. It was my first foray into web development, even if extremely basic. I knew I would have to do it eventually, but I wasn’t keen on any particular tool out there. I wanted 1) customization but also ease-of-use, 2) community support for tool development so I wouldn’t be stuck with broken code later, 3) a way to do coding in different languages and frameworks so my projects are only limited by content and not technology, and 4) I wanted ti use a tool that would persist a long time.\nQuarto seemed to fit these criteria as a new tool, support by a community, offering amazing customization and a friendly user-interface, and it fit my projects with code from different languages. I also searched for some other cool features (see the typing text on my homepage) that I could implement using Quarto. The site is also pretty mobile friendly which is a must these days! The tool seems to be great for putting together my digital garden.\nHere’s hoping we all get to see some cool content result from ‘tending’ to my digital garden!"
  },
  {
    "objectID": "content/garden/posts/20240605_ggdx_start/index.html",
    "href": "content/garden/posts/20240605_ggdx_start/index.html",
    "title": "Diagnostics in ggplot2 plots",
    "section": "",
    "text": "In my day job, every data point counts. A common objective is to visualize how an outcome or effect varies between groups of things. If the outcome varies, we posit that an a priori intervention or a mechanism may be driving the difference between things. Before generating statistics, a visual of group differences can be very persuasive.\nBelow is an example where we are plotting highway mileage between groups of cars by the number of cylinders and type of drive:\n\nlibrary(ggplot2)\n\np_base &lt;- \n    ggplot(mpg,aes(factor(cyl), hwy,fill=drv)) +\n    geom_boxplot()\np_base\n\n\n\n\n\n\n\n\nWhat is missing here is the individual cars making up the groups. A boxplot by itself tells us a 5 point summary, but people looking at a boxplot know that the distribution of data points in the plot can vary widely. Also, how do we know the groups we are comparing are valid groups to compare?\n\np_obs &lt;- \n  ggplot(mpg,aes(factor(cyl), hwy,fill=drv)) + \n    geom_point(\n        pch=21,\n        position = position_jitterdodge(\n            jitter.width = 0.2,jitter.height = 0.1,seed = 0),\n        size=3\n    ) +\n  geom_boxplot(\n      alpha=0,color='black',outlier.size=NA,\n      position = position_dodge(width=.7)\n  )\np_obs\n\n\n\n\n\n\n\n\nSeeing the data points gives us a new perspective: Whether many data points make up a group. Two boxplots may look similar, but the groups of data are not similar if only a few data points make up a boxplot. Also, we have a visual aide for the ‘tendency’ of the data in each group.\nBut we need one more thing, especially if we are dealing with small data. We need to verify that the plots capture all the data. One way to do this is to show the number of data points in each group. This can be tricky. But I have one solution taking advantage of the fact that we are using the {ggplot2} package for plotting.\nShow the number of data points in a plot by extending {ggplot2}. We extend {ggplot2} by creating new stat and geom objects - these are the building blocks for the grammar of graphics provided by {ggplot2}. Below is an example:\n\nStatCountLabel &lt;- ggproto(\"StatCountLabel\", Stat,\n                      setup_params = function(data, params) {\n                          stopifnot(is.null(params$ylower) |\n                                        is.numeric(params$ylower))\n                          \n                          if(!(params$ylower&gt;=0 & params$ylower&lt;=1))\n                              params$ylower &lt;- 0.1\n                              \n                          \n                          rng &lt;- range(data$y,na.rm=TRUE)\n                          params$ylower &lt;- rng[1] - (diff(rng)*params$ylower)\n                          params\n                      },\n                      compute_group = function(data, scales, ylower) {\n                          data |&gt; \n                              dplyr::summarise(\n                                  label = paste0(\n                                      'n = ',length(y),\n                                      '\\nmean = ',round(mean(y,na.rm=TRUE),1)\n                                      ),\n                                  y = ylower,\n                                  .by = x\n                              )\n                      },\n                      required_aes = c(\"x\", \"y\")\n)\n    \nstat_count_label &lt;- function(mapping = NULL, data = NULL, geom = \"text\",\n                       position = \"dodge2\", na.rm = FALSE, show.legend = NA, \n                       inherit.aes = TRUE, ylower = NULL,...) {\n  ggplot2::layer(\n    stat = StatCountLabel, data = data, mapping = mapping, geom = geom, \n    position = position, show.legend = show.legend, inherit.aes = inherit.aes,\n    params = list(ylower = ylower, na.rm = na.rm, ...)\n  )\n}\np_obs_n &lt;- \n  p_obs + \n  stat_count_label(\n      aes(factor(cyl), hwy,color=drv),\n      fontface='bold',size=5,\n      ylower=0.1,position = position_dodge(width=.7)\n  )\np_obs_n\n\n\n\n\n\n\n\n\nNow we have more information:\n\nSome boxplots are made up of less than 5 data points and some are made of a few dozen data points. Do we have enough evidence to say anything about differences in groups with less than 5 data points?\nThere are many cars with the same highway mileage at the bottom and upper range of the group of cars with 4-wheel drive and 6 cylinders. Should we investigate those cars for reasons why they group together?\n\nThere’s other information not listed above, but we now have a lot more information by extending {ggplot2}. The more information we have, the more confident we are in making decisions from visualizations."
  },
  {
    "objectID": "content/garden/posts/20231029_dataclasses/index.html",
    "href": "content/garden/posts/20231029_dataclasses/index.html",
    "title": "Object Oriented Programming (OOP) with Datasets",
    "section": "",
    "text": "Datasets can come in many different shapes and sizes, such as a number of rows and columns. But what if I need to interface with datasets in a specific but standard way? I can create a class for this.\nLet’s say I have two datasets that I want to represent in a standard way.\n\nd1 &lt;- datasets::airquality\nd2 &lt;- datasets::anscombe\n\n\nd1 |&gt; head(5)\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n\n\n\nd2 |&gt; head(5)\n\n  x1 x2 x3 x4   y1   y2    y3   y4\n1 10 10 10  8 8.04 9.14  7.46 6.58\n2  8  8  8  8 6.95 8.14  6.77 5.76\n3 13 13 13  8 7.58 8.74 12.74 7.71\n4  9  9  9  8 8.81 8.77  7.11 8.84\n5 11 11 11  8 8.33 9.26  7.81 8.47\n\n\nThese two example datasets are actually classes already (i.e. S3 classes), and are data.frames (which are also classes).\n\nsloop::otype(d1)\n\n[1] \"S3\"\n\nsloop::s3_class(d1)\n\n[1] \"data.frame\"\n\n\n\nsloop::otype(d2)\n\n[1] \"S3\"\n\nsloop::s3_class(d2)\n\n[1] \"data.frame\"\n\n\nSo what’s the issue if they are already classes? I actually want to know the number of rows and columns including the name of the data. That’s easy to derive, but think ‘what if they weren’t?’ - having information available would be handy. The class would then be a simple interface to that information. To that end, I would make an object with class ‘my_data’ and the below attributes. This generates a fancy list using structure:\n\nstructure(\n    list(\n        data.frame = NULL,\n        name = NULL,\n        ncols = function(x)ncol(x),\n        nrows = function(x)nrow(x)\n    ),\n    class = \"my_data\"\n)\n\n$data.frame\nNULL\n\n$name\nNULL\n\n$ncols\nfunction(x)ncol(x)\n\n$nrows\nfunction(x)nrow(x)\n\nattr(,\"class\")\n[1] \"my_data\"\n\n\nTo create objects of this class, I would create a constructor. The constructor would just be a function taking in the input and wrapping it in my new class (a fancy list):\n\nmy_data &lt;- function(dat,name = NULL){\n    stopifnot(is.data.frame(dat))\n    structure(\n    list(\n        data.frame = dat,\n        name = name,\n        ncols = ncol(dat),\n        nrows = nrow(dat)\n    ),\n    class = \"my_data\"\n    )\n}\n\nd1_data &lt;- my_data(d1,\"d1\")\nd2_data &lt;- my_data(d2,\"d2\")\n\nd1_data$name\n\n[1] \"d1\"\n\nd2_data$ncols\n\n[1] 8\n\n\nThis seems sort of useful, but what would be more useful is showing me the information I want in the way I want. To do this, I make a method for this class:\n\nshow.my_data &lt;- function(x){\n    cat(x$name,\"\\n\")\n    cat(\"Rows: \",x$nrow,\"\\n\")\n    cat(\"Columns: \",x$ncol)\n}\n\nshow &lt;- function(x){\n    UseMethod(\"show\")\n}\n\n\nshow(d1_data)\n\nd1 \nRows:  153 \nColumns:  6\n\nshow(d2_data)\n\nd2 \nRows:  11 \nColumns:  8\n\n\nI defined a show method that is specific to objects of my class. Pretty nifty. This ability gets niftier as the complexity of the attributes and the operations on objects of this class increases."
  },
  {
    "objectID": "content/garden/posts/20221229explore/index.html",
    "href": "content/garden/posts/20221229explore/index.html",
    "title": "Explorations in Pediatric Drug Safety",
    "section": "",
    "text": "In this post, I am looking into something that I have been wanting to look into for a while. This short notebook shows a mini investigation into work I did during my PhD.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(data.table)\n\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\ntheme_set(theme_bw())\n\n\nkidsides::download_sqlite_db()\n\nAlready exists: /Users/nickgiangreco/Library/Caches/org.R-project.R/R/kidsides/effect_peds_19q2_v0.3_20211119.sqlite\n\ncon &lt;- kidsides::connect_sqlite_db()\n\nIn this notebook, I want to investigate more into a claim I made in my paper on pediatric drug safety:\n\nWe investigate the relationship between development stage and known pediatric drug effects, such as montelukast-induced psychiatric disorders, where we found a significant signal (odds ratio 8.77 [2.51, 46.94]) within the second year of life.\n\nNow I’m not disputing this claim, I actually have this enrichment in the database I created:\n\ntbl(con,\"ade_nichd_enrichment\") %&gt;% \n    filter(nichd==\"toddler\" &\n               atc_concept_name==\"montelukast\" &\n               meddra_concept_name==\"Psychiatric disorders\") %&gt;% \n    collect()\n\n# A tibble: 1 × 15\n  category atc_concept_name meddra_concept_name   nichd   atc_concept_class_id\n  &lt;chr&gt;    &lt;chr&gt;            &lt;chr&gt;                 &lt;chr&gt;   &lt;chr&gt;               \n1 soc_atc5 montelukast      Psychiatric disorders toddler ATC5                \n# ℹ 10 more variables: meddra_concept_class_id &lt;chr&gt;, a &lt;int&gt;, b &lt;int&gt;,\n#   c &lt;int&gt;, d &lt;int&gt;, lwr &lt;dbl&gt;, odds_ratio &lt;dbl&gt;, upr &lt;dbl&gt;, pvalue &lt;dbl&gt;,\n#   fdr &lt;dbl&gt;\n\n\nThe odds of 8.7708426 indicates a large association of statistically significant reporting of montelukast-induced Psychiatric disorders for toddlers.\nBut, these statistics were generated using a null threshold declaring significance. I’m interested to evaluate montelukast and Psychiatric disorders having larger signal at a particular stage. Here’s my visualizations to attempt to evaluate this:\n\nmontelukast_drug_info &lt;- tbl(con,\"drug\") %&gt;%\ncollect() %&gt;%\nfilter(grepl(\"montelukast\",atc_concept_name))\n\npsych_disorder_ids &lt;- tbl(con,\"event\") %&gt;%\ncollect() %&gt;%\nfilter(grepl(\"Psych\",meddra_concept_name_4)) %&gt;%\npluck('meddra_concept_id')\n\npos &lt;- \n    position_dodge2(width=0.1)\n\ntbl(con,\"ade_nichd\") %&gt;% \n    filter(atc_concept_id==!!pluck(montelukast_drug_info,\"atc_concept_id\") &\n               meddra_concept_id %in% !!psych_disorder_ids) %&gt;% \n    collect() %&gt;% \n    mutate(\n        nichd = factor(nichd,levels=unique(nichd))\n    ) %&gt;% \n    ggplot(aes(nichd,gam_score_90mse)) +\n    geom_violin() +\n    geom_point(pch=21,size=0.2,\n               position = pos) +\n    geom_line(aes(group=ade),alpha=0.1,\n              position = pos) +\n    geom_point(\n        data=tbl(con,\"ade_null\") %&gt;% \n            collect(),\n        aes(nichd,null_99),\n        size=3,color=\"red\",\n               position = pos) +\n    theme(\n        axis.text.x = element_text(angle=45,vjust=1,hjust=1)\n    ) +\n    labs(x=\"\",y=\"90% lower dGAM signal\",caption = \"99% null dGAM in red\")\n\n\n\n\n\n\n\nprobs &lt;- seq(0,1,0.01)\ntbl(con,\"ade_nichd\") %&gt;% \n    filter(atc_concept_id==!!pluck(montelukast_drug_info,\"atc_concept_id\") &\n               meddra_concept_id %in% !!psych_disorder_ids) %&gt;% \n    collect() %&gt;% \n    mutate(\n        nichd = factor(nichd,levels=unique(nichd))\n    ) %&gt;% \n    group_by(nichd) %&gt;% \n    summarise(q = list(probs),\n              qs = \n                  list(quantile(gam_score_90mse,probs = probs))\n              ) %&gt;% \n    unnest(c(\"qs\",\"q\")) %&gt;% \n    ggplot(aes(nichd,q,fill=qs)) +\n    geom_tile() +\n    scale_y_continuous(labels = scales::percent,\n                       breaks = scales::pretty_breaks(6)) +\n    scale_fill_gradient2(low = \"purple\",\n                         midpoint = 1,high = \"red\") +\n    labs(y=\"Signal Percentile in stage\",x=\"\") +\n    guides(fill=guide_colorbar(title=\"dGAM lower\\n90% CI signal\")) +\n    theme(\n        axis.text.x = element_text(angle=45,vjust=1,hjust=1)\n    )\n\n\n\n\n\n\n\nprobs &lt;- seq(0.8,1,0.01)\ntbl(con,\"ade_nichd\") %&gt;% \n    filter(atc_concept_id==!!pluck(montelukast_drug_info,\"atc_concept_id\") &\n               meddra_concept_id %in% !!psych_disorder_ids) %&gt;% \n    collect() %&gt;% \n    mutate(\n        nichd = factor(nichd,levels=unique(nichd))\n    ) %&gt;% \n    group_by(nichd) %&gt;% \n    summarise(q = list(probs),\n              qs = \n                  list(quantile(gam_score_90mse,probs = probs))\n              ) %&gt;% \n    unnest(c(\"qs\",\"q\")) %&gt;% \n    left_join(\n        tbl(con,\"ade_null\") %&gt;% \n            collect(),\n        by=\"nichd\"\n    ) %&gt;% \n    mutate(\n        nichd = factor(nichd,levels=unique(nichd)),\n        above_null_99 = qs&gt;null_99\n    ) %&gt;% \n    ggplot(aes(nichd,q,fill=above_null_99)) +\n    geom_tile() +\n    scale_y_continuous(labels = scales::percent,\n                       breaks = scales::pretty_breaks(6)) +\n    scale_fill_brewer(palette = \"Set1\",direction = -1) +\n    labs(y=\"Signal Percentile in stage\",x=\"\") +\n    theme(\n        axis.text.x = element_text(angle=45,vjust=1,hjust=1)\n    )\n\n\n\n\n\n\n\n\nFrom these, we can see how there are large, outlier scores for montelukast induced Psychiatric disorders at the toddler stage. The score distributions are similar across toddler and childhood stages, though. Nevertheless, the last graph shows that the signals in the toddler stage are above the null 99% scores in a larger proportion of the signal distribution. So empirically, we do see that montelukast-induced Psychiatric disorders are more likely (i.e. have larger, nonrandom signal) at the toddler stage of child development.\nSince the last graph is the most definitive graph showing localization of non-random signal for this systematic disorder, we can create the graph for all montelukast-induced systematic disorders in order to evaluate non-random signal at stages:\n\ndisorders &lt;- \n    tbl(con,\"event\") %&gt;%\n    collect() %&gt;% \n    pull(meddra_concept_name_4) %&gt;% \n    na.omit() %&gt;% \n    unique()\n\npos &lt;- \n    position_dodge2(width=0.1)\nprobs &lt;- seq(0.8,1,0.01)\ncolors &lt;- RColorBrewer::brewer.pal(3,\"Set1\")[1:2]\nnames(colors) &lt;- c(\"TRUE\",\"FALSE\")\n\ng_objs &lt;- lapply(disorders,function(disorder){\n    disorder_ids &lt;- \n    tbl(con,\"event\") %&gt;%\n    collect() %&gt;%\n    filter(meddra_concept_name_4==disorder) %&gt;%\n    pluck('meddra_concept_id')\n    \n    tbl(con,\"ade_nichd\") %&gt;% \n    filter(atc_concept_id==!!pluck(montelukast_drug_info,\"atc_concept_id\") &\n               meddra_concept_id %in% !!disorder_ids) %&gt;% \n    collect() %&gt;% \n    mutate(\n        nichd = factor(nichd,levels=unique(nichd))\n    ) %&gt;% \n    group_by(nichd) %&gt;% \n    summarise(q = list(probs),\n              qs = \n                  list(quantile(gam_score_90mse,probs = probs))\n              ) %&gt;% \n    unnest(c(\"qs\",\"q\")) %&gt;% \n    left_join(\n        tbl(con,\"ade_null\") %&gt;% \n            collect(),\n        by=\"nichd\"\n    ) %&gt;% \n    mutate(\n        nichd = factor(nichd,levels=unique(nichd)),\n        above_null_99 = qs&gt;null_99\n    ) %&gt;% \n    ggplot(aes(nichd,q,fill=above_null_99)) +\n    geom_tile(show.legend = F) +\n    scale_y_continuous(labels = scales::percent,\n                       breaks = scales::pretty_breaks(6)) +\n    scale_fill_manual(values=colors) +\n    labs(y=\"\",x=\"\",title=\"\",subtitle=disorder) +\n    theme(\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank()\n    )\n})\n\nnames(g_objs) &lt;- disorders\n\ncowplot::plot_grid(plotlist=g_objs,ncol = 5)\n\n\n\n\n\n\n\n\nYou can see that few systematic disorders had higher-than-the-null signal at stages. Psychiatric disorders do seem to be uniquely induced in toddlers by montelukast.\n\nkidsides::disconnect_sqlite_db(con)"
  },
  {
    "objectID": "content/garden/posts/20230730_mccvshiny_announcement/index.html",
    "href": "content/garden/posts/20230730_mccvshiny_announcement/index.html",
    "title": "Announcing mccvshiny",
    "section": "",
    "text": "During my PhD I wrote the algorithm Monte Carlo Cross Validation (MCCV) to address a question about generating evidence for a prognostic biomarker of an adverse outcome1,2. The algorithm first ingests biomarker data from two groups, such as the concentration levels of proteins in patient’s blood samples. Next, the algorithm utilizes a subset of the biomarker data for training machine learning models (using cross validation) to mathematically separate the two groups. Then, the algorithm predicts the group for the unseen biomarker subset using the trained machine learning model. Lastly, MCCV employs this same routine many, many times for generating predictive evidence. This framework is very flexible in ingesting different data, choosing machine learning models, and how much evidence to generate. To showcase this flexibility, I turned to showcasing MCCV within a web application which also presented itself as an opportunity for learning Shiny for Python.\nmccvshiny is a Shiny for Python web application that showcases the flexibility of the prediction framework MCCV. This web application is a proof-of-concept because 1) it is computationally slow by not running the algorithm in parallel, and 2) it doesn’t incorporate as many machine learning models as is available. Notwithstanding, it’s a worthwhile application for others to learn from and it was a great learning experience for myself 😊\nClick the link here or on the GitHub site GitHub to check out the app or code. Feel free to contribute to the codebase for increasing the capabilities of the app by making a pull request (PR) on github. I’m not planning to develop the application more, but I’m happy to collaborate with others who would like to 😁 Shoutout to the Shiny team for developing a great tool for pythonistas!\n\n\n\n\nReferences\n\n1. Giangreco NP, Lebreton G, Restaino S, Jane Farr M, Zorn E, Colombo PC, Patel J, Levine R, Truby L, Soni RK, Leprince P, Kobashigawa J, Tatonetti NP, Fine BM. Plasma kallikrein predicts primary graft dysfunction after heart transplant. J. Heart Lung Transplant. 2021;40(10):1199–1211.\n\n\n2. Giangreco NP, Lebreton G, Restaino S, Farr M, Zorn E, Colombo PC, Patel J, Soni RK, Leprince P, Kobashigawa J, Tatonetti NP, Fine BM. Alterations in the kallikrein-kinin system predict death after heart transplant. Sci. Rep. 2022;12(1):14167."
  },
  {
    "objectID": "content/garden/posts/20230902_openbuffalodataforml/index.html",
    "href": "content/garden/posts/20230902_openbuffalodataforml/index.html",
    "title": "What Baby Names are In and Out of Fashion?",
    "section": "",
    "text": "Open Data Buffalo is a great resource and initiative to make datasets open and available to the public.\nMy partner works at a Children’s hospital and is convinced of trending baby names. Well, I said to her let’s see what the data says!\nSo I ventured out into the world wide web and found a dataset called:\nBaby Names: Beginning 2007\n\nNew York State (NYS) Baby Names are aggregated and displayed by the year, county, or borough where the mother resided as stated on a New York State or New York City (NYC) birth certificate. The frequency of the baby name is listed if there are 5 or more of the same baby name in a county outside of NYC or 10 or more of the same baby name in a NYC borough.\n\n\nlibrary(jsonlite)\nlibrary(RSocrata)\nsuppressMessages(library(tidyverse))\n\nbaby_names &lt;- RSocrata::read.socrata(\"https://health.data.ny.gov/resource/jxy9-yhdk.json\",app_token = read_json('.apptoken')[['token']])\n\nbaby_names %&gt;% glimpse()\n\nRows: 87,899\nColumns: 5\n$ year       &lt;chr&gt; \"2007\", \"2007\", \"2007\", \"2007\", \"2007\", \"2007\", \"2007\", \"20…\n$ first_name &lt;chr&gt; \"ZOEY\", \"ZOEY\", \"ZOEY\", \"ZOEY\", \"ZOE\", \"ZOE\", \"ZOE\", \"ZOE\",…\n$ county     &lt;chr&gt; \"KINGS\", \"SUFFOLK\", \"MONROE\", \"ERIE\", \"ULSTER\", \"WESTCHESTE…\n$ sex        &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\",…\n$ name_count &lt;chr&gt; \"11\", \"6\", \"6\", \"9\", \"5\", \"24\", \"13\", \"55\", \"15\", \"6\", \"14\"…\n\n\nThis dataset is already tidy: One row per observation (first_name or baby name) and one column per variable (e.g. the number of observed names in a county with the given gender on the birth certificate).\nI first check a few data quality characteristics such as missingness and number of unique things in each column:\n\npurrr::map_dfr(baby_names,~{sum(is.na(.x))})\n\n# A tibble: 1 × 5\n   year first_name county   sex name_count\n  &lt;int&gt;      &lt;int&gt;  &lt;int&gt; &lt;int&gt;      &lt;int&gt;\n1     0          0      0     0          0\n\npurrr::map_dfr(baby_names,~{n_distinct(.x)})\n\n# A tibble: 1 × 5\n   year first_name county   sex name_count\n  &lt;int&gt;      &lt;int&gt;  &lt;int&gt; &lt;int&gt;      &lt;int&gt;\n1    14       2320    123     2        244\n\n\n\n\nNow we need to transform our dataset by first converting columns to the appropriate data types:\n\nbaby_names_transformed &lt;- \n    baby_names %&gt;% \n    mutate(\n        year = as.integer(year),\n        first_name = factor(first_name),\n        county = factor(county),\n        sex = factor(sex,levels=c(\"M\",\"F\"),labels=c(\"Male\",\"Female\")),\n        name_count = as.integer(name_count)\n    )\n\nbaby_names_transformed %&gt;% summary()\n\n      year        first_name        county          sex          name_count    \n Min.   :2007   EMMA   :  528   Kings  : 5715   Male  :46737   Min.   :  5.00  \n 1st Qu.:2010   OLIVIA :  503   KINGS  : 4957   Female:41162   1st Qu.:  6.00  \n Median :2014   LOGAN  :  488   Suffolk: 4159                  Median : 11.00  \n Mean   :2013   MASON  :  475   SUFFOLK: 4005                  Mean   : 17.77  \n 3rd Qu.:2017   LIAM   :  471   Queens : 3868                  3rd Qu.: 19.00  \n Max.   :2020   JACOB  :  465   Nassau : 3804                  Max.   :297.00  \n                (Other):84969   (Other):61391                                  \n\n\nAfter the data transformation, we see that counties are specified in different cases. We should revise this so county (and also first_name) are in one type of case such as title case:\n\nbaby_names_transformed &lt;- \n    baby_names_transformed %&gt;% \n    mutate(\n        first_name = as.character(first_name) %&gt;% stringr::str_to_title() %&gt;% factor(),\n        county = as.character(county) %&gt;% stringr::str_to_title() %&gt;% factor()\n    )\n\nbaby_names_transformed %&gt;% summary()\n\n      year        first_name            county          sex       \n Min.   :2007   Emma   :  528   Kings      :10672   Male  :46737  \n 1st Qu.:2010   Olivia :  503   Suffolk    : 8164   Female:41162  \n Median :2014   Logan  :  488   Nassau     : 7352                 \n Mean   :2013   Mason  :  475   Queens     : 7244                 \n 3rd Qu.:2017   Liam   :  471   Westchester: 5844                 \n Max.   :2020   Jacob  :  465   Erie       : 5382                 \n                (Other):84969   (Other)    :43241                 \n   name_count    \n Min.   :  5.00  \n 1st Qu.:  6.00  \n Median : 11.00  \n Mean   : 17.77  \n 3rd Qu.: 19.00  \n Max.   :297.00  \n                 \n\n\n\n\n\nMy next data quality question is how many names have data each year?\n\ntheme_set(theme_bw(base_size = 16))\n\nbaby_names_transformed %&gt;% \n    summarize(n_years = n_distinct(year),.by=c(first_name)) %&gt;% \n    summarize(n_names = n_distinct(first_name),.by=n_years) %&gt;% \n    ggplot(aes(n_years,n_names)) +\n    geom_bar(color=\"black\",fill = \"gray80\",stat = \"identity\") +\n    scale_x_continuous(breaks = scales::pretty_breaks(14)) +\n    scale_y_continuous(expand = c(0,0.1),\n                       trans=\"sqrt\",breaks = scales::pretty_breaks(10)) +\n    labs(x=\"Year Data: Number of Years With Name Count Data\",\n         y=\"Number of Names With Year Data\",\n         title=\"Many Baby Names Don't Have Counts In A Year\",\n         subtitle=\"Every Name has Count Data For Atleast One Year\") +\n    theme(\n        panel.grid.major.y = element_line(color=\"gray75\"),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank()\n    )\n\n\n\n\n\n\n\n\n\n\n\nAnother question is are there many names that are unisex i.e. male and female names?\n\ntmp &lt;- \n    baby_names_transformed %&gt;% \n    summarize(n_sex = n_distinct(sex),\n              unisex = n_sex==2,onesex = n_sex==1,\n              .by=c(first_name)) %&gt;% \n    summarize(`Unisex` = sum(unisex),`One Sex`=sum(onesex))\n\ntmp %&gt;% \n    pivot_longer(cols = everything()) %&gt;% \n    mutate(label = glue::glue(\"{name} (N={scales::comma(value)})\")) %&gt;% \n    ggplot(aes(factor(1),value,fill=label)) +\n    geom_bar(stat=\"identity\",position = \"fill\") +\n    scale_fill_brewer(palette = \"Dark2\") +\n    scale_y_continuous(labels = scales::percent) +\n    guides(fill=guide_legend(title=NULL)) +\n    labs(x=NULL,y=\"Percent of Names\",title=\"Most Baby Names Are Gender-Specific\",subtitle = \"There Are A Few Names That Are Unisex, However\") +\n    theme(\n        axis.ticks.x = element_blank(),\n        axis.text.x = element_blank(),\n        legend.position = \"top\"\n    )\n\n\n\n\n\n\n\n\n\n\n\nMy last data quality question is how many baby names have data across counties?\n\nbaby_names_transformed %&gt;% \n    summarise(n_counties = n_distinct(county),.by=first_name) %&gt;% \n    bind_cols(\n        summarise(baby_names,total_counties = n_distinct(county))\n    ) %&gt;% \n    mutate(\n        freq_counties = n_counties / total_counties\n    ) %&gt;% \n    ggplot(aes(freq_counties,y=after_stat(count))) +\n    geom_density(bw=\"nrd\",color=\"blue\",fill=\"cornflowerblue\") +\n    scale_x_continuous(labels = scales::percent) +\n    scale_y_sqrt(breaks = scales::pretty_breaks(15)) +\n    labs(x=\"Percent of Counties\",y=\"Number of Names With County Data\",\n         title=\"Most Names are Counted in a Few NYS Counties\") +\n    theme(\n        panel.grid.major.y = element_line(color=\"gray75\"),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank()\n    )\n\n\n\n\n\n\n\n\nAfter transforming the dataset and checking data quality, we see that:\n\nBaby names are sparsely annotated across counties\nBaby names are, generally, specific to a year or are observed across all years\nThere are a few baby names that are not gender-specific.\n\n\n\n\nI want to ask the question what are the trending baby names in NYS? My question is not specific to the gender or county. Also, my question wants to consider all the baby names in the dataset as possible influencing factors in which baby names are trending. Because of the missing count data, we should use a model to estimate the trend based on the available data. The model we will use is a generalized additive model (GAM) to predict the Poisson distribution count of the baby name. **I heavily referenced https://fromthebottomoftheheap.net/2021/02/02/random-effects-in-gams/\n\n\n\nLet’s do a small example first. My subquestion is, is the baby name Charlotte trending over time irrespective of other factors?\n\nlibrary(mgcv)\n\nLoading required package: nlme\n\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nThis is mgcv 1.8-42. For overview type 'help(\"mgcv-package\")'.\n\ntmp &lt;- \n    baby_names_transformed %&gt;% \n    filter(first_name==\"Charlotte\")\n\nform &lt;- as.formula(glue::glue(\"name_count ~ s(year) + county:year\"))\nfit &lt;- mgcv::gam(form,\n                family=\"poisson\",\n                data=tmp,method = \"GACV.Cp\")\n\ntmp %&gt;% \n    bind_cols(.pred = fit$fitted.values) %&gt;% \n    ggplot(aes(name_count,.pred)) +\n    geom_point(shape=21) +\n    geom_smooth(formula = 'y ~ x',method=\"lm\") +\n    labs(x=\"Annotated Counts\",y=\"Predicted Counts\",title=\"Model Predictions Look Pretty Accurate With Not Much Bias\")\n\n\n\n\n\n\n\ncoefs_ &lt;- fit$coefficients[str_detect(names(fit$coefficients),\"s\\\\(year\\\\)\")] %&gt;% unname()\ntibble(\n    year = seq_along(coefs_),\n    coef = coefs_\n) %&gt;% \n    ggplot(aes(year,coef)) +\n    geom_line(linewidth=2) +\n    labs(x=\"Time\",y=\"Weight\",title=\"Charlotte is predicted as falling in and out of fashion\")\n\n\n\n\n\n\n\n\n\n\n\nIf we want to consider all names, we need to specify the name as a random effect and the trend line as a random slope between the name and the year:\n\n(form &lt;- as.formula(glue::glue(\"name_count ~ s(first_name, bs = 're') + s(first_name, year, bs = 're') + county:year + sex:year\")))\n\nname_count ~ s(first_name, bs = \"re\") + s(first_name, year, bs = \"re\") + \n    county:year + sex:year\n\n\nWe can use this formula in our model to get the trends of the baby names over time (Note: we switch from gam to bam so that we can fit the model faster using method = ‘fREML’):\n\ntmp &lt;- \n    baby_names_transformed\n\nif(file.exists(paste0(here::here(),\"/baby_name_gam_full.rds\"))){\n    fit &lt;- readr::read_rds(paste0(here::here(),\"/baby_name_gam_full.rds\"))\n}else{\n    system.time(fit &lt;- mgcv::bam(form,\n                 family = \"poisson\",\n                 data = tmp,\n                 discrete = TRUE))\n    readr::write_rds(fit,paste0(here::here(),\"/baby_name_gam_full.rds\"))\n}\n\nNow we combine the predicted baby name counts to the original data:\n\n(data_pred &lt;- \n        bind_cols(tmp,\n                  as.data.frame(predict(fit,\n                                        new_data = tmp,\n                                        se.fit = TRUE))) %&gt;% \n        tibble())\n\n# A tibble: 87,899 × 7\n    year first_name county      sex    name_count   fit se.fit\n   &lt;int&gt; &lt;fct&gt;      &lt;fct&gt;       &lt;fct&gt;       &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1  2007 Zoey       Kings       Female         11  3.58 0.0206\n 2  2007 Zoey       Suffolk     Female          6  3.09 0.0207\n 3  2007 Zoey       Monroe      Female          6  2.39 0.0210\n 4  2007 Zoey       Erie        Female          9  2.59 0.0209\n 5  2007 Zoe        Ulster      Female          5  1.68 0.0200\n 6  2007 Zoe        Westchester Female         24  3.15 0.0155\n 7  2007 Zoe        Bronx       Female         13  3.69 0.0153\n 8  2007 Zoe        New York    Female         55  3.61 0.0153\n 9  2007 Zoe        Nassau      Female         15  3.45 0.0153\n10  2007 Zoe        Erie        Female          6  3.09 0.0155\n# ℹ 87,889 more rows\n\n\nAnd we can now plot predicted baby name trends over time:\n\npred_baby_names &lt;- \n    data_pred %&gt;% \n    summarize(avg_pred = mean(fit),.by=c(first_name,year))\n\npred_baby_names %&gt;% \n    ggplot(aes(year,avg_pred,group=first_name)) +\n    geom_line(show.legend = F,color=\"gray80\") +\n    scale_x_continuous(breaks = scales::pretty_breaks(14)) +\n    labs(x=\"Year\",y=\"Average Prediction Across Counties and Sex\") +\n    theme(\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.x = element_line(color=\"gray95\"),\n        panel.grid.minor.x = element_blank()\n    )\n\n\n\n\n\n\n\n\nNow we have trend estimates for baby names over time considering the naming variability across counties, gender, and years.\n\n\n\nWe can now ask the question what are the top trending baby names in NY?\n\n(top_10_baby_names &lt;- \n    pred_baby_names %&gt;% \n    summarise(cor = cor(year,avg_pred,method=\"spearman\"),.by = first_name) %&gt;% \n    slice_max(order_by = cor,n = 10,with_ties = F))\n\n# A tibble: 10 × 2\n   first_name   cor\n   &lt;fct&gt;      &lt;dbl&gt;\n 1 Reed           1\n 2 Aviva          1\n 3 Raelynn        1\n 4 Talya          1\n 5 Sebastien      1\n 6 Patricia       1\n 7 Lesley         1\n 8 Katelynn       1\n 9 Hillary        1\n10 Gershon        1\n\npred_baby_names %&gt;% \n    filter(first_name %in% top_10_baby_names$first_name) %&gt;% \n    ggplot(aes(year,avg_pred,color=first_name)) +\n    geom_line(linewidth=1) +\n    scale_x_continuous(breaks = scales::pretty_breaks(14)) +\n    labs(x=\"Year\",y=\"Average Prediction\",title=\"Missing Data Cast Doubt On Baby Name Trends\") +\n    guides(color=guide_legend(title=NULL)) +\n    theme(\n        legend.position = \"bottom\"\n    )\n\n\n\n\n\n\n\n\nLooks like I need to add a variable for the name attributing how many years worth of count data it has as well as if it was a name in 2019 or 2020.\n\n(pred_baby_names &lt;- \n    pred_baby_names %&gt;% \n    left_join(\n        data_pred %&gt;% \n        summarise(n_years = n_distinct(year),prop_years = n_years/14,\n                  recent = any(year %in% c(2019,2020)),.by=first_name),\n        by = \"first_name\"\n    ))\n\n# A tibble: 16,166 × 6\n   first_name  year avg_pred n_years prop_years recent\n   &lt;fct&gt;      &lt;int&gt;    &lt;dbl&gt;   &lt;int&gt;      &lt;dbl&gt; &lt;lgl&gt; \n 1 Zoey        2007     2.91      14      1     TRUE  \n 2 Zoe         2007     3.21      14      1     TRUE  \n 3 Zissy       2007     2.50      14      1     TRUE  \n 4 Zion        2007     3.02      14      1     TRUE  \n 5 Zev         2007     3.00      14      1     TRUE  \n 6 Zara        2007     2.79      14      1     TRUE  \n 7 Zaire       2007     2.68      13      0.929 TRUE  \n 8 Zackary     2007     1.87       2      0.143 FALSE \n 9 Zachary     2007     2.23      14      1     TRUE  \n10 Yusuf       2007     2.26      13      0.929 TRUE  \n# ℹ 16,156 more rows\n\n\n\n\n\nNow we can ask what are the top 10 trending baby names that are recently popular?\n\n(top_10_recent_baby_names &lt;- \n    pred_baby_names %&gt;% \n    filter(recent & prop_years&gt;.5) %&gt;% \n    summarise(cor = cor(year,avg_pred,method=\"spearman\"),.by = first_name) %&gt;% \n    slice_max(order_by = cor,n = 10,with_ties = F))\n\n# A tibble: 10 × 2\n   first_name   cor\n   &lt;fct&gt;      &lt;dbl&gt;\n 1 Tyler      0.982\n 2 Joshua     0.974\n 3 Alyssa     0.965\n 4 Nicholas   0.947\n 5 Aiden      0.947\n 6 Jacob      0.925\n 7 Kaylee     0.921\n 8 Aidan      0.912\n 9 Abigail    0.912\n10 Ryan       0.908\n\npred_baby_names %&gt;% \n    filter(first_name %in% top_10_recent_baby_names$first_name) %&gt;% \n    mutate(first_name = factor(first_name,top_10_recent_baby_names$first_name)) %&gt;% \n    ggplot(aes(year,avg_pred,color=first_name)) +\n    geom_line(linewidth=1) +\n    scale_x_continuous(breaks = scales::pretty_breaks(14)) +\n    labs(x=\"Year\",y=\"Average Prediction\",title=\"Top 10 Trending Names\") +\n    guides(color=guide_legend(title=NULL)) +\n    theme(\n        legend.position = \"top\"\n    )\n\n\n\n\n\n\n\npred_baby_names %&gt;% \n    filter(first_name %in% top_10_recent_baby_names$first_name) %&gt;% \n    mutate(first_name = factor(first_name,top_10_recent_baby_names$first_name)) %&gt;% \n    ggplot(aes(year,avg_pred,color=first_name)) +\n    geom_line(linewidth=1,show.legend = FALSE) +\n    scale_x_continuous(breaks = scales::pretty_breaks(14)) +\n    facet_wrap(~first_name,ncol=3) +\n    labs(x=\"Year\",y=\"Average Prediction\",title=\"Top 10 Baby Trending Names\") +\n    theme(\n        axis.text.x = element_text(angle=90,vjust=1,hjust=1)\n    )\n\n\n\n\n\n\n\n\nSo there we go! This seems accurate, as a top trending baby name is Nicholas and my nephew’s name (born in 2018) is Aiden 🤓\nAnd here is a summary table with the trending baby names in order:\n\npred_baby_names %&gt;% \n    summarise(cor = cor(year,avg_pred,method=\"spearman\"),\n              .by = c(first_name,recent,prop_years)) %&gt;% \n    arrange(desc(recent),desc(prop_years),desc(cor)) %&gt;% \n    DT::datatable()\n\n\n\n\n\nThis was a fun post and exploration of trending baby names in NYS. If you made it this far, I hope you enjoyed reading 😁"
  },
  {
    "objectID": "content/garden/posts/20230902_openbuffalodataforml/index.html#the-baby_names-dataset-requires-initial-preprocessing",
    "href": "content/garden/posts/20230902_openbuffalodataforml/index.html#the-baby_names-dataset-requires-initial-preprocessing",
    "title": "What Baby Names are In and Out of Fashion?",
    "section": "",
    "text": "Now we need to transform our dataset by first converting columns to the appropriate data types:\n\nbaby_names_transformed &lt;- \n    baby_names %&gt;% \n    mutate(\n        year = as.integer(year),\n        first_name = factor(first_name),\n        county = factor(county),\n        sex = factor(sex,levels=c(\"M\",\"F\"),labels=c(\"Male\",\"Female\")),\n        name_count = as.integer(name_count)\n    )\n\nbaby_names_transformed %&gt;% summary()\n\n      year        first_name        county          sex          name_count    \n Min.   :2007   EMMA   :  528   Kings  : 5715   Male  :46737   Min.   :  5.00  \n 1st Qu.:2010   OLIVIA :  503   KINGS  : 4957   Female:41162   1st Qu.:  6.00  \n Median :2014   LOGAN  :  488   Suffolk: 4159                  Median : 11.00  \n Mean   :2013   MASON  :  475   SUFFOLK: 4005                  Mean   : 17.77  \n 3rd Qu.:2017   LIAM   :  471   Queens : 3868                  3rd Qu.: 19.00  \n Max.   :2020   JACOB  :  465   Nassau : 3804                  Max.   :297.00  \n                (Other):84969   (Other):61391                                  \n\n\nAfter the data transformation, we see that counties are specified in different cases. We should revise this so county (and also first_name) are in one type of case such as title case:\n\nbaby_names_transformed &lt;- \n    baby_names_transformed %&gt;% \n    mutate(\n        first_name = as.character(first_name) %&gt;% stringr::str_to_title() %&gt;% factor(),\n        county = as.character(county) %&gt;% stringr::str_to_title() %&gt;% factor()\n    )\n\nbaby_names_transformed %&gt;% summary()\n\n      year        first_name            county          sex       \n Min.   :2007   Emma   :  528   Kings      :10672   Male  :46737  \n 1st Qu.:2010   Olivia :  503   Suffolk    : 8164   Female:41162  \n Median :2014   Logan  :  488   Nassau     : 7352                 \n Mean   :2013   Mason  :  475   Queens     : 7244                 \n 3rd Qu.:2017   Liam   :  471   Westchester: 5844                 \n Max.   :2020   Jacob  :  465   Erie       : 5382                 \n                (Other):84969   (Other)    :43241                 \n   name_count    \n Min.   :  5.00  \n 1st Qu.:  6.00  \n Median : 11.00  \n Mean   : 17.77  \n 3rd Qu.: 19.00  \n Max.   :297.00"
  },
  {
    "objectID": "content/garden/posts/20230902_openbuffalodataforml/index.html#many-baby-names-dont-have-counts-in-a-year",
    "href": "content/garden/posts/20230902_openbuffalodataforml/index.html#many-baby-names-dont-have-counts-in-a-year",
    "title": "What Baby Names are In and Out of Fashion?",
    "section": "",
    "text": "My next data quality question is how many names have data each year?\n\ntheme_set(theme_bw(base_size = 16))\n\nbaby_names_transformed %&gt;% \n    summarize(n_years = n_distinct(year),.by=c(first_name)) %&gt;% \n    summarize(n_names = n_distinct(first_name),.by=n_years) %&gt;% \n    ggplot(aes(n_years,n_names)) +\n    geom_bar(color=\"black\",fill = \"gray80\",stat = \"identity\") +\n    scale_x_continuous(breaks = scales::pretty_breaks(14)) +\n    scale_y_continuous(expand = c(0,0.1),\n                       trans=\"sqrt\",breaks = scales::pretty_breaks(10)) +\n    labs(x=\"Year Data: Number of Years With Name Count Data\",\n         y=\"Number of Names With Year Data\",\n         title=\"Many Baby Names Don't Have Counts In A Year\",\n         subtitle=\"Every Name has Count Data For Atleast One Year\") +\n    theme(\n        panel.grid.major.y = element_line(color=\"gray75\"),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank()\n    )"
  },
  {
    "objectID": "content/garden/posts/20230902_openbuffalodataforml/index.html#most-baby-names-are-gender-specific",
    "href": "content/garden/posts/20230902_openbuffalodataforml/index.html#most-baby-names-are-gender-specific",
    "title": "What Baby Names are In and Out of Fashion?",
    "section": "",
    "text": "Another question is are there many names that are unisex i.e. male and female names?\n\ntmp &lt;- \n    baby_names_transformed %&gt;% \n    summarize(n_sex = n_distinct(sex),\n              unisex = n_sex==2,onesex = n_sex==1,\n              .by=c(first_name)) %&gt;% \n    summarize(`Unisex` = sum(unisex),`One Sex`=sum(onesex))\n\ntmp %&gt;% \n    pivot_longer(cols = everything()) %&gt;% \n    mutate(label = glue::glue(\"{name} (N={scales::comma(value)})\")) %&gt;% \n    ggplot(aes(factor(1),value,fill=label)) +\n    geom_bar(stat=\"identity\",position = \"fill\") +\n    scale_fill_brewer(palette = \"Dark2\") +\n    scale_y_continuous(labels = scales::percent) +\n    guides(fill=guide_legend(title=NULL)) +\n    labs(x=NULL,y=\"Percent of Names\",title=\"Most Baby Names Are Gender-Specific\",subtitle = \"There Are A Few Names That Are Unisex, However\") +\n    theme(\n        axis.ticks.x = element_blank(),\n        axis.text.x = element_blank(),\n        legend.position = \"top\"\n    )"
  },
  {
    "objectID": "content/garden/posts/20230902_openbuffalodataforml/index.html#most-baby-names-are-counted-in-a-few-nys-counties",
    "href": "content/garden/posts/20230902_openbuffalodataforml/index.html#most-baby-names-are-counted-in-a-few-nys-counties",
    "title": "What Baby Names are In and Out of Fashion?",
    "section": "",
    "text": "My last data quality question is how many baby names have data across counties?\n\nbaby_names_transformed %&gt;% \n    summarise(n_counties = n_distinct(county),.by=first_name) %&gt;% \n    bind_cols(\n        summarise(baby_names,total_counties = n_distinct(county))\n    ) %&gt;% \n    mutate(\n        freq_counties = n_counties / total_counties\n    ) %&gt;% \n    ggplot(aes(freq_counties,y=after_stat(count))) +\n    geom_density(bw=\"nrd\",color=\"blue\",fill=\"cornflowerblue\") +\n    scale_x_continuous(labels = scales::percent) +\n    scale_y_sqrt(breaks = scales::pretty_breaks(15)) +\n    labs(x=\"Percent of Counties\",y=\"Number of Names With County Data\",\n         title=\"Most Names are Counted in a Few NYS Counties\") +\n    theme(\n        panel.grid.major.y = element_line(color=\"gray75\"),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank()\n    )\n\n\n\n\n\n\n\n\nAfter transforming the dataset and checking data quality, we see that:\n\nBaby names are sparsely annotated across counties\nBaby names are, generally, specific to a year or are observed across all years\nThere are a few baby names that are not gender-specific."
  },
  {
    "objectID": "content/garden/posts/20230902_openbuffalodataforml/index.html#what-are-the-trending-baby-names-in-nys",
    "href": "content/garden/posts/20230902_openbuffalodataforml/index.html#what-are-the-trending-baby-names-in-nys",
    "title": "What Baby Names are In and Out of Fashion?",
    "section": "",
    "text": "I want to ask the question what are the trending baby names in NYS? My question is not specific to the gender or county. Also, my question wants to consider all the baby names in the dataset as possible influencing factors in which baby names are trending. Because of the missing count data, we should use a model to estimate the trend based on the available data. The model we will use is a generalized additive model (GAM) to predict the Poisson distribution count of the baby name. **I heavily referenced https://fromthebottomoftheheap.net/2021/02/02/random-effects-in-gams/"
  },
  {
    "objectID": "content/garden/posts/20230902_openbuffalodataforml/index.html#we-can-estimate-baby-name-trends-using-generalized-additive-models",
    "href": "content/garden/posts/20230902_openbuffalodataforml/index.html#we-can-estimate-baby-name-trends-using-generalized-additive-models",
    "title": "What Baby Names are In and Out of Fashion?",
    "section": "",
    "text": "Let’s do a small example first. My subquestion is, is the baby name Charlotte trending over time irrespective of other factors?\n\nlibrary(mgcv)\n\nLoading required package: nlme\n\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nThis is mgcv 1.8-42. For overview type 'help(\"mgcv-package\")'.\n\ntmp &lt;- \n    baby_names_transformed %&gt;% \n    filter(first_name==\"Charlotte\")\n\nform &lt;- as.formula(glue::glue(\"name_count ~ s(year) + county:year\"))\nfit &lt;- mgcv::gam(form,\n                family=\"poisson\",\n                data=tmp,method = \"GACV.Cp\")\n\ntmp %&gt;% \n    bind_cols(.pred = fit$fitted.values) %&gt;% \n    ggplot(aes(name_count,.pred)) +\n    geom_point(shape=21) +\n    geom_smooth(formula = 'y ~ x',method=\"lm\") +\n    labs(x=\"Annotated Counts\",y=\"Predicted Counts\",title=\"Model Predictions Look Pretty Accurate With Not Much Bias\")\n\n\n\n\n\n\n\ncoefs_ &lt;- fit$coefficients[str_detect(names(fit$coefficients),\"s\\\\(year\\\\)\")] %&gt;% unname()\ntibble(\n    year = seq_along(coefs_),\n    coef = coefs_\n) %&gt;% \n    ggplot(aes(year,coef)) +\n    geom_line(linewidth=2) +\n    labs(x=\"Time\",y=\"Weight\",title=\"Charlotte is predicted as falling in and out of fashion\")"
  },
  {
    "objectID": "content/garden/posts/20230902_openbuffalodataforml/index.html#gams-allow-for-estimating-trends-given-random-naming-patterns-across-nys-counties-over-time",
    "href": "content/garden/posts/20230902_openbuffalodataforml/index.html#gams-allow-for-estimating-trends-given-random-naming-patterns-across-nys-counties-over-time",
    "title": "What Baby Names are In and Out of Fashion?",
    "section": "",
    "text": "If we want to consider all names, we need to specify the name as a random effect and the trend line as a random slope between the name and the year:\n\n(form &lt;- as.formula(glue::glue(\"name_count ~ s(first_name, bs = 're') + s(first_name, year, bs = 're') + county:year + sex:year\")))\n\nname_count ~ s(first_name, bs = \"re\") + s(first_name, year, bs = \"re\") + \n    county:year + sex:year\n\n\nWe can use this formula in our model to get the trends of the baby names over time (Note: we switch from gam to bam so that we can fit the model faster using method = ‘fREML’):\n\ntmp &lt;- \n    baby_names_transformed\n\nif(file.exists(paste0(here::here(),\"/baby_name_gam_full.rds\"))){\n    fit &lt;- readr::read_rds(paste0(here::here(),\"/baby_name_gam_full.rds\"))\n}else{\n    system.time(fit &lt;- mgcv::bam(form,\n                 family = \"poisson\",\n                 data = tmp,\n                 discrete = TRUE))\n    readr::write_rds(fit,paste0(here::here(),\"/baby_name_gam_full.rds\"))\n}\n\nNow we combine the predicted baby name counts to the original data:\n\n(data_pred &lt;- \n        bind_cols(tmp,\n                  as.data.frame(predict(fit,\n                                        new_data = tmp,\n                                        se.fit = TRUE))) %&gt;% \n        tibble())\n\n# A tibble: 87,899 × 7\n    year first_name county      sex    name_count   fit se.fit\n   &lt;int&gt; &lt;fct&gt;      &lt;fct&gt;       &lt;fct&gt;       &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1  2007 Zoey       Kings       Female         11  3.58 0.0206\n 2  2007 Zoey       Suffolk     Female          6  3.09 0.0207\n 3  2007 Zoey       Monroe      Female          6  2.39 0.0210\n 4  2007 Zoey       Erie        Female          9  2.59 0.0209\n 5  2007 Zoe        Ulster      Female          5  1.68 0.0200\n 6  2007 Zoe        Westchester Female         24  3.15 0.0155\n 7  2007 Zoe        Bronx       Female         13  3.69 0.0153\n 8  2007 Zoe        New York    Female         55  3.61 0.0153\n 9  2007 Zoe        Nassau      Female         15  3.45 0.0153\n10  2007 Zoe        Erie        Female          6  3.09 0.0155\n# ℹ 87,889 more rows\n\n\nAnd we can now plot predicted baby name trends over time:\n\npred_baby_names &lt;- \n    data_pred %&gt;% \n    summarize(avg_pred = mean(fit),.by=c(first_name,year))\n\npred_baby_names %&gt;% \n    ggplot(aes(year,avg_pred,group=first_name)) +\n    geom_line(show.legend = F,color=\"gray80\") +\n    scale_x_continuous(breaks = scales::pretty_breaks(14)) +\n    labs(x=\"Year\",y=\"Average Prediction Across Counties and Sex\") +\n    theme(\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        panel.grid.major.x = element_line(color=\"gray95\"),\n        panel.grid.minor.x = element_blank()\n    )\n\n\n\n\n\n\n\n\nNow we have trend estimates for baby names over time considering the naming variability across counties, gender, and years."
  },
  {
    "objectID": "content/garden/posts/20230902_openbuffalodataforml/index.html#gam-estimates-offer-robust-baby-name-trends-but-still-need-to-consider-data-missingness",
    "href": "content/garden/posts/20230902_openbuffalodataforml/index.html#gam-estimates-offer-robust-baby-name-trends-but-still-need-to-consider-data-missingness",
    "title": "What Baby Names are In and Out of Fashion?",
    "section": "",
    "text": "We can now ask the question what are the top trending baby names in NY?\n\n(top_10_baby_names &lt;- \n    pred_baby_names %&gt;% \n    summarise(cor = cor(year,avg_pred,method=\"spearman\"),.by = first_name) %&gt;% \n    slice_max(order_by = cor,n = 10,with_ties = F))\n\n# A tibble: 10 × 2\n   first_name   cor\n   &lt;fct&gt;      &lt;dbl&gt;\n 1 Reed           1\n 2 Aviva          1\n 3 Raelynn        1\n 4 Talya          1\n 5 Sebastien      1\n 6 Patricia       1\n 7 Lesley         1\n 8 Katelynn       1\n 9 Hillary        1\n10 Gershon        1\n\npred_baby_names %&gt;% \n    filter(first_name %in% top_10_baby_names$first_name) %&gt;% \n    ggplot(aes(year,avg_pred,color=first_name)) +\n    geom_line(linewidth=1) +\n    scale_x_continuous(breaks = scales::pretty_breaks(14)) +\n    labs(x=\"Year\",y=\"Average Prediction\",title=\"Missing Data Cast Doubt On Baby Name Trends\") +\n    guides(color=guide_legend(title=NULL)) +\n    theme(\n        legend.position = \"bottom\"\n    )\n\n\n\n\n\n\n\n\nLooks like I need to add a variable for the name attributing how many years worth of count data it has as well as if it was a name in 2019 or 2020.\n\n(pred_baby_names &lt;- \n    pred_baby_names %&gt;% \n    left_join(\n        data_pred %&gt;% \n        summarise(n_years = n_distinct(year),prop_years = n_years/14,\n                  recent = any(year %in% c(2019,2020)),.by=first_name),\n        by = \"first_name\"\n    ))\n\n# A tibble: 16,166 × 6\n   first_name  year avg_pred n_years prop_years recent\n   &lt;fct&gt;      &lt;int&gt;    &lt;dbl&gt;   &lt;int&gt;      &lt;dbl&gt; &lt;lgl&gt; \n 1 Zoey        2007     2.91      14      1     TRUE  \n 2 Zoe         2007     3.21      14      1     TRUE  \n 3 Zissy       2007     2.50      14      1     TRUE  \n 4 Zion        2007     3.02      14      1     TRUE  \n 5 Zev         2007     3.00      14      1     TRUE  \n 6 Zara        2007     2.79      14      1     TRUE  \n 7 Zaire       2007     2.68      13      0.929 TRUE  \n 8 Zackary     2007     1.87       2      0.143 FALSE \n 9 Zachary     2007     2.23      14      1     TRUE  \n10 Yusuf       2007     2.26      13      0.929 TRUE  \n# ℹ 16,156 more rows"
  },
  {
    "objectID": "content/garden/posts/20230902_openbuffalodataforml/index.html#filtering-our-gam-estimates-can-give-more-reliable-top-trending-baby-names-in-nys",
    "href": "content/garden/posts/20230902_openbuffalodataforml/index.html#filtering-our-gam-estimates-can-give-more-reliable-top-trending-baby-names-in-nys",
    "title": "What Baby Names are In and Out of Fashion?",
    "section": "",
    "text": "Now we can ask what are the top 10 trending baby names that are recently popular?\n\n(top_10_recent_baby_names &lt;- \n    pred_baby_names %&gt;% \n    filter(recent & prop_years&gt;.5) %&gt;% \n    summarise(cor = cor(year,avg_pred,method=\"spearman\"),.by = first_name) %&gt;% \n    slice_max(order_by = cor,n = 10,with_ties = F))\n\n# A tibble: 10 × 2\n   first_name   cor\n   &lt;fct&gt;      &lt;dbl&gt;\n 1 Tyler      0.982\n 2 Joshua     0.974\n 3 Alyssa     0.965\n 4 Nicholas   0.947\n 5 Aiden      0.947\n 6 Jacob      0.925\n 7 Kaylee     0.921\n 8 Aidan      0.912\n 9 Abigail    0.912\n10 Ryan       0.908\n\npred_baby_names %&gt;% \n    filter(first_name %in% top_10_recent_baby_names$first_name) %&gt;% \n    mutate(first_name = factor(first_name,top_10_recent_baby_names$first_name)) %&gt;% \n    ggplot(aes(year,avg_pred,color=first_name)) +\n    geom_line(linewidth=1) +\n    scale_x_continuous(breaks = scales::pretty_breaks(14)) +\n    labs(x=\"Year\",y=\"Average Prediction\",title=\"Top 10 Trending Names\") +\n    guides(color=guide_legend(title=NULL)) +\n    theme(\n        legend.position = \"top\"\n    )\n\n\n\n\n\n\n\npred_baby_names %&gt;% \n    filter(first_name %in% top_10_recent_baby_names$first_name) %&gt;% \n    mutate(first_name = factor(first_name,top_10_recent_baby_names$first_name)) %&gt;% \n    ggplot(aes(year,avg_pred,color=first_name)) +\n    geom_line(linewidth=1,show.legend = FALSE) +\n    scale_x_continuous(breaks = scales::pretty_breaks(14)) +\n    facet_wrap(~first_name,ncol=3) +\n    labs(x=\"Year\",y=\"Average Prediction\",title=\"Top 10 Baby Trending Names\") +\n    theme(\n        axis.text.x = element_text(angle=90,vjust=1,hjust=1)\n    )\n\n\n\n\n\n\n\n\nSo there we go! This seems accurate, as a top trending baby name is Nicholas and my nephew’s name (born in 2018) is Aiden 🤓\nAnd here is a summary table with the trending baby names in order:\n\npred_baby_names %&gt;% \n    summarise(cor = cor(year,avg_pred,method=\"spearman\"),\n              .by = c(first_name,recent,prop_years)) %&gt;% \n    arrange(desc(recent),desc(prop_years),desc(cor)) %&gt;% \n    DT::datatable()\n\n\n\n\n\nThis was a fun post and exploration of trending baby names in NYS. If you made it this far, I hope you enjoyed reading 😁"
  },
  {
    "objectID": "content/garden/posts/20230730_openbuffalodata/index.html",
    "href": "content/garden/posts/20230730_openbuffalodata/index.html",
    "title": "Identifying Open Data about the City of Buffalo and Western New York",
    "section": "",
    "text": "Open Data Buffalo is a great resource and initiative to make datasets open and available to the public. My goal looking here is to identify and download available datasets about my hometown. This is the first leg of the journey in order to perform analyses or create web applications that do something interesting, fun, and possibly useful with data from my hometown. Along thhe way, I hope to learn more about APIs, Shiny development, and knowledge about the place I call home.\nLet’s get started!\nI first made an account with Tyler Data and Insights. Not sure why, but I may learn why later on.\nSecond, I searched for datasets and sorted by most accessed datasets.\n\n\n\nScreenshot of search filter and sorted site\n\n\nAnd after scrolling through a few pages, I’m curious to look at the Active Corporations dataset.\n\n\n\n\n\n\n\nScreenshot of Active Corporations dataset webpage\n\n\nLuckily, this dataset has a few options to access the data:\n\n\n\nScreenshot of API options\n\n\nAnd below is some information about the dataset on the webpage. It has 3.6 million rows and 30 columns.\n\n\n\n\n\n\n\nScreenshot of Active Corporations dataset description\n\n\nLet’s see what happens when I try to view this dataset.\n\nlibrary(jsonlite)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\njobj &lt;- jsonlite::read_json(\"https://data.ny.gov/resource/n9v6-gdp6.json\",simplifyVector = TRUE)\n\njobj %&gt;% dplyr::glimpse()\n\nRows: 1,000\nColumns: 30\n$ dos_id                     &lt;chr&gt; \"4072354\", \"6221345\", \"4265810\", \"1330171\",…\n$ current_entity_name        &lt;chr&gt; \"GRACE SEAFOOD CORP.\", \"KV CATALYST IM, LLC…\n$ initial_dos_filing_date    &lt;chr&gt; \"2011-03-24T00:00:00.000\", \"2021-07-15T00:0…\n$ county                     &lt;chr&gt; \"Bronx\", \"New York\", \"Queens\", \"Cayuga\", \"B…\n$ jurisdiction               &lt;chr&gt; \"New York\", \"Delaware\", \"New York\", \"New Yo…\n$ entity_type                &lt;chr&gt; \"DOMESTIC BUSINESS CORPORATION\", \"FOREIGN L…\n$ dos_process_name           &lt;chr&gt; \"GRACE SEAFOOD CORP.\", \"KV CATALYST IM, LLC…\n$ dos_process_address_1      &lt;chr&gt; \"1226 EAST 183RD STREET\", \"2373 BROADWAY, A…\n$ dos_process_city           &lt;chr&gt; \"BRONX\", \"NEW YORK\", \"MIDDLE VILLAGE\", \"AUB…\n$ dos_process_state          &lt;chr&gt; \"NY\", \"NY\", \"NY\", \"NY\", \"NY\", \"NY\", \"NY\", \"…\n$ dos_process_zip            &lt;chr&gt; \"10453\", \"10024\", \"11379\", \"13021\", \"10467\"…\n$ chairman_name              &lt;chr&gt; NA, NA, NA, \"GARY J. CUNNINGHAM, JR.\", NA, …\n$ chairman_address_1         &lt;chr&gt; NA, NA, NA, \"GARY J. CUNNINGHAM, JR.\", NA, …\n$ chairman_city              &lt;chr&gt; NA, NA, NA, \"AUBURN\", NA, \"BRONX\", \"ATLANTI…\n$ chairman_state             &lt;chr&gt; NA, NA, NA, \"NY\", NA, \"NY\", \"NY\", \"NY\", NA,…\n$ chairman_zip               &lt;chr&gt; NA, NA, NA, \"130210251\", NA, \"10469\", \"1150…\n$ location_name              &lt;chr&gt; NA, NA, NA, \"YAWGER BROOK BAKES, INC.\", NA,…\n$ location_address_1         &lt;chr&gt; NA, NA, NA, \"C/O GARY J. CUNNINGHAM, JR.\", …\n$ location_address_2         &lt;chr&gt; NA, NA, NA, \"323 CLARK ST\", NA, \"1ST FL\", N…\n$ location_city              &lt;chr&gt; NA, NA, NA, \"AUBURN\", NA, \"BRONX\", \"ATLANTI…\n$ location_state             &lt;chr&gt; NA, NA, NA, \"NY\", NA, \"NY\", \"NY\", \"NY\", NA,…\n$ location_zip               &lt;chr&gt; NA, NA, NA, \"13021\", NA, \"10469\", \"11509\", …\n$ dos_process_address_2      &lt;chr&gt; NA, NA, NA, NA, NA, \"1ST FL\", NA, NA, NA, \"…\n$ chairman_address_2         &lt;chr&gt; NA, NA, NA, NA, NA, \"1ST FL\", NA, NA, NA, N…\n$ registered_agent_name      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ registered_agent_address_1 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ registered_agent_city      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ registered_agent_state     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ registered_agent_zip       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ registered_agent_address_2 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n\n\nInteresting! I may come back to this but let’s see what another dataset looks like. The dataset description is on the site below.\n\n\n\nScreenshot of Inpatient Discharge dataset.\n\n\n\njobj &lt;- jsonlite::read_json(\"https://health.data.ny.gov/resource/u4ud-w55t.json\",simplifyVector = TRUE)\n\njobj %&gt;% dplyr::glimpse()\n\nRows: 1,000\nColumns: 34\n$ hospital_service_area               &lt;chr&gt; \"Capital/Adirond\", \"Capital/Adiron…\n$ hospital_county                     &lt;chr&gt; \"Albany\", \"Albany\", \"Albany\", \"Alb…\n$ operating_certificate_number        &lt;chr&gt; \"0101000\", \"0101000\", \"0101000\", \"…\n$ facility_id                         &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\",…\n$ facility_name                       &lt;chr&gt; \"Albany Medical Center Hospital\", …\n$ age_group                           &lt;chr&gt; \"0 to 17\", \"0 to 17\", \"18 to 29\", …\n$ zip_code_3_digits                   &lt;chr&gt; \"121\", \"121\", \"120\", \"121\", \"124\",…\n$ gender                              &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"M\", \"F\", \"M\",…\n$ race                                &lt;chr&gt; \"Other Race\", \"White\", \"White\", \"W…\n$ ethnicity                           &lt;chr&gt; \"Not Span/Hispanic\", \"Not Span/His…\n$ length_of_stay                      &lt;chr&gt; \"1\", \"1\", \"3\", \"2\", \"3\", \"3\", \"3\",…\n$ type_of_admission                   &lt;chr&gt; \"Urgent\", \"Emergency\", \"Urgent\", \"…\n$ patient_disposition                 &lt;chr&gt; \"Home or Self Care\", \"Home or Self…\n$ discharge_year                      &lt;chr&gt; \"2012\", \"2012\", \"2012\", \"2012\", \"2…\n$ ccs_diagnosis_code                  &lt;chr&gt; \"128\", \"251\", \"184\", \"189\", \"042\",…\n$ ccs_diagnosis_description           &lt;chr&gt; \"Asthma\", \"Abdominal pain\", \"Early…\n$ ccs_procedure_code                  &lt;chr&gt; \"000\", \"000\", \"000\", \"134\", \"090\",…\n$ ccs_procedure_description           &lt;chr&gt; \"NO PROC\", \"NO PROC\", \"NO PROC\", \"…\n$ apr_drg_code                        &lt;chr&gt; \"141\", \"251\", \"563\", \"540\", \"224\",…\n$ apr_drg_description                 &lt;chr&gt; \"Asthma\", \"Abdominal pain\", \"Prete…\n$ apr_mdc_code                        &lt;chr&gt; \"04\", \"06\", \"14\", \"14\", \"06\", \"14\"…\n$ apr_mdc_description                 &lt;chr&gt; \"Diseases and Disorders of the Res…\n$ apr_severity_of_illness_code        &lt;chr&gt; \"2\", \"1\", \"2\", \"1\", \"2\", \"1\", \"1\",…\n$ apr_severity_of_illness_description &lt;chr&gt; \"Moderate\", \"Minor\", \"Moderate\", \"…\n$ apr_risk_of_mortality               &lt;chr&gt; \"Minor\", \"Minor\", \"Minor\", \"Minor\"…\n$ apr_medical_surgical_description    &lt;chr&gt; \"Medical\", \"Medical\", \"Medical\", \"…\n$ source_of_payment_1                 &lt;chr&gt; \"Medicaid\", \"Medicaid\", \"Medicaid\"…\n$ source_of_payment_2                 &lt;chr&gt; \"Medicaid\", \"Self-Pay\", \"Medicaid\"…\n$ source_of_payment_3                 &lt;chr&gt; \"Self-Pay\", NA, \"Self-Pay\", NA, \"S…\n$ birth_weight                        &lt;chr&gt; \"0000\", \"0000\", \"0000\", \"0000\", \"0…\n$ abortion_edit_indicator             &lt;chr&gt; \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\",…\n$ emergency_department_indicator      &lt;chr&gt; \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"N\",…\n$ total_charges                       &lt;chr&gt; \"9965.25\", \"6685.95\", \"12885.00\", …\n$ total_costs                         &lt;chr&gt; \"3269.66\", \"2148.08\", \"4132.75\", \"…\n\n\nIt looks like I’m only downloading 1000 rows from each dataset. Hmmm. It looks like I can export the button by pressing the ‘Export’ button, but I don’t want to have datasets on my laptop. I rather load them into my environment as needed by whatever I would end up developing. Maybe I need to read these SODA docs that are linked on the site.\n\n\n\n\n\n\n\nScreenshot of SODA Getting Started docs\n\n\nSo it seems like I need to use some extra parameter filtering? Let’s try it.\n\njobj &lt;- jsonlite::read_json(\"https://health.data.ny.gov/resource/u4ud-w55t.json?apr_drg_description=Asthma\",simplifyVector = TRUE)\n\njobj %&gt;% dplyr::glimpse()\n\nRows: 1,000\nColumns: 34\n$ hospital_service_area               &lt;chr&gt; \"Capital/Adirond\", \"Capital/Adiron…\n$ hospital_county                     &lt;chr&gt; \"Albany\", \"Albany\", \"Albany\", \"Alb…\n$ operating_certificate_number        &lt;chr&gt; \"0101000\", \"0101000\", \"0101000\", \"…\n$ facility_id                         &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\",…\n$ facility_name                       &lt;chr&gt; \"Albany Medical Center Hospital\", …\n$ age_group                           &lt;chr&gt; \"0 to 17\", \"0 to 17\", \"0 to 17\", \"…\n$ zip_code_3_digits                   &lt;chr&gt; \"121\", \"124\", \"128\", \"OOS\", \"124\",…\n$ gender                              &lt;chr&gt; \"F\", \"M\", \"M\", \"M\", \"M\", \"F\", \"M\",…\n$ race                                &lt;chr&gt; \"Other Race\", \"White\", \"Other Race…\n$ ethnicity                           &lt;chr&gt; \"Not Span/Hispanic\", \"Not Span/His…\n$ length_of_stay                      &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\",…\n$ type_of_admission                   &lt;chr&gt; \"Urgent\", \"Urgent\", \"Urgent\", \"Urg…\n$ patient_disposition                 &lt;chr&gt; \"Home or Self Care\", \"Home or Self…\n$ discharge_year                      &lt;chr&gt; \"2012\", \"2012\", \"2012\", \"2012\", \"2…\n$ ccs_diagnosis_code                  &lt;chr&gt; \"128\", \"128\", \"128\", \"128\", \"128\",…\n$ ccs_diagnosis_description           &lt;chr&gt; \"Asthma\", \"Asthma\", \"Asthma\", \"Ast…\n$ ccs_procedure_code                  &lt;chr&gt; \"000\", \"000\", \"000\", \"000\", \"000\",…\n$ ccs_procedure_description           &lt;chr&gt; \"NO PROC\", \"NO PROC\", \"NO PROC\", \"…\n$ apr_drg_code                        &lt;chr&gt; \"141\", \"141\", \"141\", \"141\", \"141\",…\n$ apr_drg_description                 &lt;chr&gt; \"Asthma\", \"Asthma\", \"Asthma\", \"Ast…\n$ apr_mdc_code                        &lt;chr&gt; \"04\", \"04\", \"04\", \"04\", \"04\", \"04\"…\n$ apr_mdc_description                 &lt;chr&gt; \"Diseases and Disorders of the Res…\n$ apr_severity_of_illness_code        &lt;chr&gt; \"2\", \"1\", \"2\", \"2\", \"1\", \"1\", \"1\",…\n$ apr_severity_of_illness_description &lt;chr&gt; \"Moderate\", \"Minor\", \"Moderate\", \"…\n$ apr_risk_of_mortality               &lt;chr&gt; \"Minor\", \"Minor\", \"Minor\", \"Minor\"…\n$ apr_medical_surgical_description    &lt;chr&gt; \"Medical\", \"Medical\", \"Medical\", \"…\n$ source_of_payment_1                 &lt;chr&gt; \"Medicaid\", \"Managed Care, Unspeci…\n$ source_of_payment_2                 &lt;chr&gt; \"Medicaid\", \"Self-Pay\", \"Self-Pay\"…\n$ source_of_payment_3                 &lt;chr&gt; \"Self-Pay\", NA, NA, NA, NA, NA, NA…\n$ birth_weight                        &lt;chr&gt; \"0000\", \"0000\", \"0000\", \"0000\", \"0…\n$ abortion_edit_indicator             &lt;chr&gt; \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\",…\n$ emergency_department_indicator      &lt;chr&gt; \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\",…\n$ total_charges                       &lt;chr&gt; \"9965.25\", \"7003.18\", \"3458.39\", \"…\n$ total_costs                         &lt;chr&gt; \"3269.66\", \"2313.70\", \"1175.09\", \"…\n\n\nI think that worked - I only downloaded Asthma items! But still, a limited dataset of 1000 rows was downloaded. What do I need to download all items? Ah, looks like I need to read about the application token usage.\n\n\n\nScreenshot of throttling and application tokens\n\n\nI must use an App token. I will create one in my profile settings - this must be why my previous self made the account earlier on in this post. Huzzah! So now that I created an app token, let’s try using it. I’ll use the glue package to read it in from a hidden file so I don’t have it sown here 😁\n\nlibrary(glue)\n\njobj &lt;- jsonlite::read_json(glue::glue(\"https://health.data.ny.gov/resource/u4ud-w55t.json?$$app_token={read_json('.apptoken')[['token']]}\"),simplifyVector = T)\n\njobj %&gt;% dplyr::glimpse()\n\nRows: 1,000\nColumns: 34\n$ hospital_service_area               &lt;chr&gt; \"Capital/Adirond\", \"Capital/Adiron…\n$ hospital_county                     &lt;chr&gt; \"Albany\", \"Albany\", \"Albany\", \"Alb…\n$ operating_certificate_number        &lt;chr&gt; \"0101000\", \"0101000\", \"0101000\", \"…\n$ facility_id                         &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\",…\n$ facility_name                       &lt;chr&gt; \"Albany Medical Center Hospital\", …\n$ age_group                           &lt;chr&gt; \"0 to 17\", \"0 to 17\", \"18 to 29\", …\n$ zip_code_3_digits                   &lt;chr&gt; \"121\", \"121\", \"120\", \"121\", \"124\",…\n$ gender                              &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"M\", \"F\", \"M\",…\n$ race                                &lt;chr&gt; \"Other Race\", \"White\", \"White\", \"W…\n$ ethnicity                           &lt;chr&gt; \"Not Span/Hispanic\", \"Not Span/His…\n$ length_of_stay                      &lt;chr&gt; \"1\", \"1\", \"3\", \"2\", \"3\", \"3\", \"3\",…\n$ type_of_admission                   &lt;chr&gt; \"Urgent\", \"Emergency\", \"Urgent\", \"…\n$ patient_disposition                 &lt;chr&gt; \"Home or Self Care\", \"Home or Self…\n$ discharge_year                      &lt;chr&gt; \"2012\", \"2012\", \"2012\", \"2012\", \"2…\n$ ccs_diagnosis_code                  &lt;chr&gt; \"128\", \"251\", \"184\", \"189\", \"042\",…\n$ ccs_diagnosis_description           &lt;chr&gt; \"Asthma\", \"Abdominal pain\", \"Early…\n$ ccs_procedure_code                  &lt;chr&gt; \"000\", \"000\", \"000\", \"134\", \"090\",…\n$ ccs_procedure_description           &lt;chr&gt; \"NO PROC\", \"NO PROC\", \"NO PROC\", \"…\n$ apr_drg_code                        &lt;chr&gt; \"141\", \"251\", \"563\", \"540\", \"224\",…\n$ apr_drg_description                 &lt;chr&gt; \"Asthma\", \"Abdominal pain\", \"Prete…\n$ apr_mdc_code                        &lt;chr&gt; \"04\", \"06\", \"14\", \"14\", \"06\", \"14\"…\n$ apr_mdc_description                 &lt;chr&gt; \"Diseases and Disorders of the Res…\n$ apr_severity_of_illness_code        &lt;chr&gt; \"2\", \"1\", \"2\", \"1\", \"2\", \"1\", \"1\",…\n$ apr_severity_of_illness_description &lt;chr&gt; \"Moderate\", \"Minor\", \"Moderate\", \"…\n$ apr_risk_of_mortality               &lt;chr&gt; \"Minor\", \"Minor\", \"Minor\", \"Minor\"…\n$ apr_medical_surgical_description    &lt;chr&gt; \"Medical\", \"Medical\", \"Medical\", \"…\n$ source_of_payment_1                 &lt;chr&gt; \"Medicaid\", \"Medicaid\", \"Medicaid\"…\n$ source_of_payment_2                 &lt;chr&gt; \"Medicaid\", \"Self-Pay\", \"Medicaid\"…\n$ source_of_payment_3                 &lt;chr&gt; \"Self-Pay\", NA, \"Self-Pay\", NA, \"S…\n$ birth_weight                        &lt;chr&gt; \"0000\", \"0000\", \"0000\", \"0000\", \"0…\n$ abortion_edit_indicator             &lt;chr&gt; \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\",…\n$ emergency_department_indicator      &lt;chr&gt; \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"N\",…\n$ total_charges                       &lt;chr&gt; \"9965.25\", \"6685.95\", \"12885.00\", …\n$ total_costs                         &lt;chr&gt; \"3269.66\", \"2148.08\", \"4132.75\", \"…\n\n\nHmmm still a limited dataset downloaded even with the app token. Let’s see if there is an http message.\n\nlibrary(httr)\nres &lt;- httr::GET(glue::glue(\"https://health.data.ny.gov/resource/u4ud-w55t.json?$$app_token={read_json('.apptoken')[['token']]}\"))\n\nnames(res)\n\n [1] \"url\"         \"status_code\" \"headers\"     \"all_headers\" \"cookies\"    \n [6] \"content\"     \"date\"        \"times\"       \"request\"     \"handle\"     \n\nres$status_code\n\n[1] 200\n\nrlist &lt;- httr::content(res)\n\ndo.call(dplyr::bind_rows, rlist) %&gt;% dplyr::glimpse()\n\nRows: 1,000\nColumns: 34\n$ hospital_service_area               &lt;chr&gt; \"Capital/Adirond\", \"Capital/Adiron…\n$ hospital_county                     &lt;chr&gt; \"Albany\", \"Albany\", \"Albany\", \"Alb…\n$ operating_certificate_number        &lt;chr&gt; \"0101000\", \"0101000\", \"0101000\", \"…\n$ facility_id                         &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\",…\n$ facility_name                       &lt;chr&gt; \"Albany Medical Center Hospital\", …\n$ age_group                           &lt;chr&gt; \"0 to 17\", \"0 to 17\", \"18 to 29\", …\n$ zip_code_3_digits                   &lt;chr&gt; \"121\", \"121\", \"120\", \"121\", \"124\",…\n$ gender                              &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"M\", \"F\", \"M\",…\n$ race                                &lt;chr&gt; \"Other Race\", \"White\", \"White\", \"W…\n$ ethnicity                           &lt;chr&gt; \"Not Span/Hispanic\", \"Not Span/His…\n$ length_of_stay                      &lt;chr&gt; \"1\", \"1\", \"3\", \"2\", \"3\", \"3\", \"3\",…\n$ type_of_admission                   &lt;chr&gt; \"Urgent\", \"Emergency\", \"Urgent\", \"…\n$ patient_disposition                 &lt;chr&gt; \"Home or Self Care\", \"Home or Self…\n$ discharge_year                      &lt;chr&gt; \"2012\", \"2012\", \"2012\", \"2012\", \"2…\n$ ccs_diagnosis_code                  &lt;chr&gt; \"128\", \"251\", \"184\", \"189\", \"042\",…\n$ ccs_diagnosis_description           &lt;chr&gt; \"Asthma\", \"Abdominal pain\", \"Early…\n$ ccs_procedure_code                  &lt;chr&gt; \"000\", \"000\", \"000\", \"134\", \"090\",…\n$ ccs_procedure_description           &lt;chr&gt; \"NO PROC\", \"NO PROC\", \"NO PROC\", \"…\n$ apr_drg_code                        &lt;chr&gt; \"141\", \"251\", \"563\", \"540\", \"224\",…\n$ apr_drg_description                 &lt;chr&gt; \"Asthma\", \"Abdominal pain\", \"Prete…\n$ apr_mdc_code                        &lt;chr&gt; \"04\", \"06\", \"14\", \"14\", \"06\", \"14\"…\n$ apr_mdc_description                 &lt;chr&gt; \"Diseases and Disorders of the Res…\n$ apr_severity_of_illness_code        &lt;chr&gt; \"2\", \"1\", \"2\", \"1\", \"2\", \"1\", \"1\",…\n$ apr_severity_of_illness_description &lt;chr&gt; \"Moderate\", \"Minor\", \"Moderate\", \"…\n$ apr_risk_of_mortality               &lt;chr&gt; \"Minor\", \"Minor\", \"Minor\", \"Minor\"…\n$ apr_medical_surgical_description    &lt;chr&gt; \"Medical\", \"Medical\", \"Medical\", \"…\n$ source_of_payment_1                 &lt;chr&gt; \"Medicaid\", \"Medicaid\", \"Medicaid\"…\n$ source_of_payment_2                 &lt;chr&gt; \"Medicaid\", \"Self-Pay\", \"Medicaid\"…\n$ source_of_payment_3                 &lt;chr&gt; \"Self-Pay\", NA, \"Self-Pay\", NA, \"S…\n$ birth_weight                        &lt;chr&gt; \"0000\", \"0000\", \"0000\", \"0000\", \"0…\n$ abortion_edit_indicator             &lt;chr&gt; \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\",…\n$ emergency_department_indicator      &lt;chr&gt; \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"N\",…\n$ total_charges                       &lt;chr&gt; \"9965.25\", \"6685.95\", \"12885.00\", …\n$ total_costs                         &lt;chr&gt; \"3269.66\", \"2148.08\", \"4132.75\", \"…\n\n\nNot that I can tell, and still a limited dataset is downloaded. After some google searches, I found the {RSocrata} that may be helpful.\n\nlibrary(RSocrata)\ndat &lt;- RSocrata::read.socrata(\"https://health.data.ny.gov/resource/u4ud-w55t.json\",app_token = read_json('.apptoken')[['token']])\n\ndat %&gt;% dplyr::glimpse()\n\nRows: 2,544,543\nColumns: 34\n$ hospital_service_area               &lt;chr&gt; \"Western NY\", \"Western NY\", \"Weste…\n$ hospital_county                     &lt;chr&gt; \"Allegany\", \"Allegany\", \"Allegany\"…\n$ operating_certificate_number        &lt;chr&gt; \"0226700\", \"0226700\", \"0226700\", \"…\n$ facility_id                         &lt;chr&gt; \"37\", \"37\", \"37\", \"37\", \"37\", \"37\"…\n$ facility_name                       &lt;chr&gt; \"Cuba Memorial Hospital Inc\", \"Cub…\n$ age_group                           &lt;chr&gt; \"30 to 49\", \"70 or Older\", \"30 to …\n$ zip_code_3_digits                   &lt;chr&gt; \"147\", \"147\", \"147\", \"147\", \"147\",…\n$ gender                              &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"M\",…\n$ race                                &lt;chr&gt; \"White\", \"White\", \"White\", \"White\"…\n$ ethnicity                           &lt;chr&gt; \"Not Span/Hispanic\", \"Not Span/His…\n$ length_of_stay                      &lt;chr&gt; \"4\", \"4\", \"3\", \"1\", \"3\", \"1\", \"3\",…\n$ type_of_admission                   &lt;chr&gt; \"Elective\", \"Urgent\", \"Urgent\", \"U…\n$ patient_disposition                 &lt;chr&gt; \"Home or Self Care\", \"Short-term H…\n$ discharge_year                      &lt;chr&gt; \"2012\", \"2012\", \"2012\", \"2012\", \"2…\n$ ccs_diagnosis_code                  &lt;chr&gt; \"122\", \"197\", \"122\", \"122\", \"122\",…\n$ ccs_diagnosis_description           &lt;chr&gt; \"Pneumonia (except that caused by …\n$ ccs_procedure_code                  &lt;chr&gt; \"000\", \"000\", \"000\", \"000\", \"000\",…\n$ ccs_procedure_description           &lt;chr&gt; \"NO PROC\", \"NO PROC\", \"NO PROC\", \"…\n$ apr_drg_code                        &lt;chr&gt; \"139\", \"383\", \"139\", \"139\", \"139\",…\n$ apr_drg_description                 &lt;chr&gt; \"Other pneumonia\", \"Cellulitis & o…\n$ apr_mdc_code                        &lt;chr&gt; \"04\", \"09\", \"04\", \"04\", \"04\", \"06\"…\n$ apr_mdc_description                 &lt;chr&gt; \"Diseases and Disorders of the Res…\n$ apr_severity_of_illness_code        &lt;chr&gt; \"1\", \"3\", \"1\", \"1\", \"2\", \"1\", \"2\",…\n$ apr_severity_of_illness_description &lt;chr&gt; \"Minor\", \"Major\", \"Minor\", \"Minor\"…\n$ apr_risk_of_mortality               &lt;chr&gt; \"Minor\", \"Major\", \"Minor\", \"Minor\"…\n$ apr_medical_surgical_description    &lt;chr&gt; \"Medical\", \"Medical\", \"Medical\", \"…\n$ source_of_payment_1                 &lt;chr&gt; \"Blue Cross/Blue Shield\", \"Medicar…\n$ birth_weight                        &lt;chr&gt; \"0000\", \"0000\", \"0000\", \"0000\", \"0…\n$ abortion_edit_indicator             &lt;chr&gt; \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\",…\n$ emergency_department_indicator      &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\",…\n$ total_charges                       &lt;chr&gt; \"5511.95\", \"4783.20\", \"3829.15\", \"…\n$ total_costs                         &lt;chr&gt; \"5582.49\", \"5162.82\", \"4056.52\", \"…\n$ source_of_payment_2                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ source_of_payment_3                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nEureka! This downloaded a full dataset. So seems like I can use this package to start reading in and playing with full datasets. I can also use the API to make smaller requests based on filters, too. Tis will be better in the long run since I don’t want to have to download entire datasets. But maybe I will once and store using {arrow} so a web app or notebook doesn’t make a lot of API calls. We shall see how this journey unfolds!\nHope this train of thought is useful to you readers! I’ll definitely come back to this."
  },
  {
    "objectID": "content/garden/posts/20241215_aws_open_data_arrow/index.html",
    "href": "content/garden/posts/20241215_aws_open_data_arrow/index.html",
    "title": "Looking up open datasets in AWS Marketplace using {arrow}",
    "section": "",
    "text": "Have you ever wanted to dive into huge biological datasets, do a little citizen science, or just sharpen your coding skills? AWS Open Data Registry is a treasure trove of public datasets you can access for free! Today, we’ll explore the Clinical Proteomic Tumor Analysis Consortium (CPTAC-2) dataset.\nCPTAC-2 is part of a national effort to accelerate our understanding of cancer biology through proteogenomics. The datasets include RNA-Seq, miRNA quantification, and other valuable tools for cancer research. Exciting stuff, right? Let’s access and explore it using R and packages like {arrow} and {purrr}."
  },
  {
    "objectID": "content/garden/posts/20241215_aws_open_data_arrow/index.html#connecting-to-aws-s3-storage",
    "href": "content/garden/posts/20241215_aws_open_data_arrow/index.html#connecting-to-aws-s3-storage",
    "title": "Looking up open datasets in AWS Marketplace using {arrow}",
    "section": "Connecting to AWS S3 Storage",
    "text": "Connecting to AWS S3 Storage\nThe CPTAC data lives on an S3 bucket in AWS. To access it, we’ll use arrow::s3_bucket. The {arrow} package makes working with cloud storage and large datasets seamless. Let’s set up the connection:\n\n# Connect to the CPTAC-2 open data bucket on AWS\ncptac_s3 &lt;- arrow::s3_bucket(\"s3://gdc-cptac-2-phs000892-2-open/\")\n\nBoom! We now have a pipeline into the bucket, and we can start peeking at its contents."
  },
  {
    "objectID": "content/garden/posts/20241215_aws_open_data_arrow/index.html#listing-folders-and-files",
    "href": "content/garden/posts/20241215_aws_open_data_arrow/index.html#listing-folders-and-files",
    "title": "Looking up open datasets in AWS Marketplace using {arrow}",
    "section": "Listing Folders and Files",
    "text": "Listing Folders and Files\nThe first step is to see what’s inside this giant bucket.\n\nListing Folders\n\n# List all folders in the bucket\ncptac_folders &lt;- cptac_s3$ls()\nlength(cptac_folders)\n\n[1] 3984\n\ncptac_folders[1:5]\n\n[1] \"00308a6b-56f8-4e51-9b4b-500ca6d32387\"\n[2] \"006fc0cd-8419-4278-887b-ee922340fd85\"\n[3] \"0088029e-05f1-461c-a30a-2d6628a7f8d2\"\n[4] \"00997ac4-8cc4-4c90-a2ab-d4a36068faf0\"\n[5] \"00d681ae-9382-4224-a8a2-d51fd4dbaa28\"\n\n\nHere, cptac_s3$ls() gives us the top-level folder names in the bucket.\n\n\nListing Files in Each Folder\nNow that we have folders, let’s dive into them and list the files inside. We’ll use the purrr::map_chr() function to map over the folders and fetch the file names.\n\n# List all files within the folders\ncptac_files &lt;- purrr::map_chr(\n    cptac_folders,\n    ~{ cptac_s3$ls(.x) }\n)\nlength(cptac_files)\n\n[1] 3984\n\ncptac_files[1:5]\n\n[1] \"00308a6b-56f8-4e51-9b4b-500ca6d32387/35036955-3a03-4b7a-bd55-d8bc721f99c4.htseq_counts.txt.gz\"                   \n[2] \"006fc0cd-8419-4278-887b-ee922340fd85/fcc26511-0b8b-4914-ad7e-bb97a3cd03f8.FPKM-UQ.txt.gz\"                        \n[3] \"0088029e-05f1-461c-a30a-2d6628a7f8d2/34566acf-5f1f-4b7c-859a-5c7c2c38ed8e.wxs.aliquot_ensemble_masked.maf.gz\"    \n[4] \"00997ac4-8cc4-4c90-a2ab-d4a36068faf0/4dc10240-c4ca-4b92-866b-af1542575fc8.rna_seq.augmented_star_gene_counts.tsv\"\n[5] \"00d681ae-9382-4224-a8a2-d51fd4dbaa28/c2de32e3-b9bc-49e1-9dbe-8c09b48ff637.htseq_counts.txt.gz\"                   \n\n\nThis step takes each folder and retrieves the files within."
  },
  {
    "objectID": "content/garden/posts/20241215_aws_open_data_arrow/index.html#classifying-file-types",
    "href": "content/garden/posts/20241215_aws_open_data_arrow/index.html#classifying-file-types",
    "title": "Looking up open datasets in AWS Marketplace using {arrow}",
    "section": "Classifying File Types",
    "text": "Classifying File Types\nLet’s get curious: what types of data are in these files? We’ll extract file extensions to see what formats are available.\n\n# Extract file types by splitting filenames\ncptac_filetypes &lt;- purrr::map_chr(\n    cptac_files,\n    ~{\n        (basename(.x) |&gt; \n         stringr::str_split_fixed(pattern = \"\\\\.\", n = 2))[2]\n    }\n)\n\n# Count the occurrences of each file type\ntable(cptac_filetypes)\n\ncptac_filetypes\n                        FPKM-UQ.txt.gz                            FPKM.txt.gz \n                                   340                                    340 \n                   htseq_counts.txt.gz   mirnaseq.isoforms.quantification.txt \n                                   340                                    650 \n    mirnaseq.mirnas.quantification.txt rna_seq.augmented_star_gene_counts.tsv \n                                   650                                    340 \n       rna_seq.star_gene_counts.tsv.gz     wxs.aliquot_ensemble_masked.maf.gz \n                                   340                                    984 \n\n\nHere, we: 1. Use basename() to get the file name without the folder path. 2. Split the file name at the first dot (\\\\.) to extract extensions. 3. Count the file types using table().\nThis gives us a nice summary of the types of files: .txt.gz, .tsv, and so on."
  },
  {
    "objectID": "content/garden/posts/20240128_nfldashboard_update/index.html",
    "href": "content/garden/posts/20240128_nfldashboard_update/index.html",
    "title": "The end of the beginning to a NFL player performance dashboard",
    "section": "",
    "text": "The NFL Data Dashboard Project\nMy last post outlined the start of my new hobby project: creation of a sports analytics dashboard. There was a fun intersection between me wanting to work on a fun project in a new domain and my brother having keen expertise in Fantasy Football (FF) and the NFL. I set out to learn new techniques in application/software development, which also led to fun discussion on factors contributing to NFL player performance.\n\n\nEvery Dashboard Needs a Prototype\nThe goal of the dashboard is to display NFL statistics for deciding on winning FF rosters*. A dashboard that exactly reached that goal is highly sought after! Obviously, it would take significant time, resources, and critical evaluation to create such a dashboard, which would challenge even a well-funded company. Additionally, the approach to reaching this goal will change. The potential insights from and interactions with the data in the dashboard change with more understanding of the data and presentation of that data. Therefore, we need a prototype!*A winning FF roster has a set of players with the most FF points during the season\n\n\nThe Journey to a Prototype\nThe prototype we created helped us think about our overall goal*. We wanted to not only directly compare players, but also compare players week by week during the season. We wanted to not only compare players to all others, but think about overall player performance with their variability during the season. After a few football discussions and leveraging key programming techniques, we created the current version of the dashboard that does a pretty good job towards our goal. Below are two graphs displaying performance of QBs (see the dashboard for statistic descriptions):https://github.com/ngiangre/nfldatadashboard\n\n\n\nBoxplot with scatter points of all QBs as gray dots, and the AFC/NFC team QBs as colored point amongst them for each performance statistic\n\n\n\n\n\nScatterplot of all QBs as gray points and the AFC/NFC team QBs as colored points faceted by different performance statistics\n\n\n\n\nAll Prototypes Serve a Purpose\nSimilar to Plato’s allegory of the cave*, prototypes are just shadows of the “ideal” dashboard. In my opinion, prototypes have more purpose than shadows because they can lead us to the “ideal” dashboard that reaches our goal. How many prototypes do we need to make to reach our goal? That is the million, possibly billion, dollar question! Luckily, in this fun hobby project, I’ll probably chase a few shadows that get us to ‘good enough’ while balancing fun and the limited time I can work on this.https://en.wikipedia.org/wiki/Allegory_of_the_cave\n\n\nAll Prototypes Have an Ending\nThe development of this prototype is coming to an end. The prototype helped us move towards the dashboard’s ‘ideal’ goal, but has ultimately led to a new approach we want to explore. What are the trends of players across seasons? Are they lifting off in their career? Are there other data sources, such as of player injuries or contracts, that can yield some interesting insights into pivotal points in player’s careers? The current prototype was not designed for development in this direction, and so developing this prototype has come to an end.\n\n\nAll Prototypes Beget Another Prototype\nThe ‘death’ of one prototype leading to the ‘birth’ of another prototype is actually quite poetic. And as is often the case, the next prototype is arguably more insightful and impactful than the first. Fortunately, all that was learned when developing the first prototype can be used when developing the next! This strengthens our skills in software/application development just like practicing for a piano recital, or for a Superbowl. For the application/software developers out there, enoy the journey and keep prototyping!\nClick here for link to Github repository\nClick here for link to live dashboard"
  },
  {
    "objectID": "content/garden/posts/20250101_fast_fold_change_calculation/index.html",
    "href": "content/garden/posts/20250101_fast_fold_change_calculation/index.html",
    "title": "Computing group differences fast",
    "section": "",
    "text": "I had a thought for computing the fold change of the average of two distributions. Below is my attempt to try out something - a {data.table} and a {dplyr} implementation. The {data.table} approach doesn’t scale well compared to the {dplyr} approach so I must have did something wrong with the syntax. Using the {dtplyr} package actually helps in this case with translating to the right syntax for the speed ups afforded by {data.table}. However the {dplyr} function actually outperforms the function using {dtplyr}. However, the {dplyr} implentation is still pretty slow at the scale I ideally want to target…need to think this implentation through…\n\ncreate_dataset &lt;- function(n=1e6,n_tests = 2,n_groups = 3){\n    stopifnot(is.numeric(n_groups) & n_groups&gt;0)\n    stopifnot(is.numeric(n_tests) & n_tests&gt;0)\n    eg &lt;- expand.grid(1:n_groups,1:n_tests)\n    var1 &lt;- eg[['Var1']]\n    var2 &lt;- eg[['Var2']]\n    purrr::map2_dfr(\n        var1,\n        var2,\n    function(grp,name){\n        data.table::data.table(\n            \"group\" = grp,\n            \"name\" = name,\n            \"value\" = rgamma(n,sample(1:10,1),sample(1:10,1))\n            )\n        })\n}\ndat &lt;- create_dataset(n=10,n_tests = 1,n_groups = 2)\ndim(dat)\n\n[1] 20  3\n\nhead(dat)\n\n   group name    value\n1:     1    1 7.214747\n2:     1    1 5.734305\n3:     1    1 3.698168\n4:     1    1 2.566807\n5:     1    1 3.387825\n6:     1    1 4.297761\n\n\n\nlibrary(data.table)\ncompute_fc_dt &lt;- function(df, measurement_col, group_cols, value_col = \"value\") {\n    if (!requireNamespace(\"data.table\", quietly = TRUE)) {\n        stop(\"The 'data.table' package is required but not installed.\")\n    }\n    \n    # Convert to data.table and validate input\n    dt &lt;- as.data.table(df)\n    stopifnot(value_col %in% colnames(dt),\n              all(group_cols %in% colnames(dt)),\n              measurement_col %in% colnames(dt))\n    \n    # Ensure the value column is numeric and remove NA values\n    dt &lt;- dt[!is.na(get(value_col))]\n    dt[[value_col]] &lt;- as.numeric(dt[[value_col]])\n    \n    # Compute fold changes for all group column combinations\n    final_result &lt;- purrr::map_dfr(unique(dt[[measurement_col]]),function(measure){\n        dt_measure &lt;- dt[get(measurement_col) == measure]\n        \n        # Compute fold changes for each group column\n        purrr::map_dfr(group_cols,function(group_col){\n            levels &lt;- unique(dt_measure[[group_col]])\n            combos &lt;- combn(levels, 2, simplify = FALSE)\n            \n            # Calculate fold changes for each pair of levels\n            purrr::map_dfr(combos,function(combo){\n                group1 &lt;- combo[1]\n                group2 &lt;- combo[2]\n                \n                # Compute means for each group\n                mean1 &lt;- dt_measure[get(group_col) == group1, mean(get(value_col), na.rm = TRUE)]\n                mean2 &lt;- dt_measure[get(group_col) == group2, mean(get(value_col), na.rm = TRUE)]\n                \n                # Calculate fold change and avoid division by zero\n                fold_change &lt;- mean1 / mean2\n                if (fold_change &lt; 1) fold_change &lt;- 1 / fold_change\n                \n                # Append the result to the list\n                data.table(\n                    measurement = measure,\n                    group_col = group_col,\n                    group1 = group1,\n                    group2 = group2,\n                    AVAL = fold_change\n                )\n            })\n        })\n    })\n    \n    # Combine results and add analysis column\n    final_result[['PARAM']] = \"fold_change\"\n    return(final_result)\n}\ncompute_fc_dplyr &lt;- function(df, measurement_col, group_cols, value_col = \"value\") {\n    if (!requireNamespace(\"data.table\", quietly = TRUE)) {\n        stop(\"The 'data.table' package is required but not installed.\")\n    }\n    \n    # Convert to data.table and validate input\n    dt &lt;- tibble::as_tibble(df)\n    stopifnot(value_col %in% colnames(dt),\n              all(group_cols %in% colnames(dt)),\n              measurement_col %in% colnames(dt))\n    \n    # Ensure the value column is numeric and remove NA values\n    dt &lt;- \n        dt |&gt; \n        dplyr::filter(!is.na(.data[[value_col]])) |&gt; \n        dplyr::mutate(\n            dplyr::across(dplyr::all_of(value_col), as.numeric)\n        )\n    \n    # Compute fold changes\n    result &lt;- \n        unique(dt[[measurement_col]]) |&gt; \n        purrr::map_dfr(function(measure) {\n            dt_measure &lt;- \n                dt |&gt; \n                dplyr::filter(.data[[measurement_col]] == measure)\n            \n            group_cols |&gt;\n                purrr::map_dfr(function(group_col) {\n                    dt_measure |&gt; \n                        dplyr::summarise(\n                            mean_value = mean(.data[[value_col]], na.rm = TRUE), \n                            .by = dplyr::all_of(group_col)\n                        ) |&gt; \n                        dplyr::summarise(\n                            AVAL = mean_value[1] / mean_value[2],\n                            group_value1 = .data[[group_col]][1], \n                            group_value2 = .data[[group_col]][2],\n                            group_column = group_col,\n                            !!measurement_col := measure\n                        )\n                })\n        }) |&gt; \n        dplyr::mutate(\n            PARAM = \"fold_change\"\n        ) |&gt; \n        dplyr::relocate(\n            dplyr::any_of(c(\n                \"group_column\",measurement_col,\n                \"group_value1\",\"group_value2\",\n                \"PARAM\",\"AVAL\"\n            ))\n        )\n    \n    return(result)\n}\ncompute_fc_dtplyr &lt;- function(df, measurement_col, group_cols, value_col = \"value\") {\n    if (!requireNamespace(\"data.table\", quietly = TRUE)) {\n        stop(\"The 'data.table' package is required but not installed.\")\n    }\n    \n    # Convert to data.table and validate input\n    stopifnot(value_col %in% colnames(df),\n              all(group_cols %in% colnames(df)),\n              measurement_col %in% colnames(df))\n    \n    # Ensure the value column is numeric and remove NA values\n    dt &lt;- \n        df |&gt; \n        dtplyr::lazy_dt() |&gt; \n        dplyr::filter(!is.na(.data[[value_col]])) |&gt; \n        dplyr::mutate(\n            dplyr::across(dplyr::all_of(value_col), as.numeric)\n        )\n    \n    # Compute fold changes\n    result &lt;- \n        unique(df[[measurement_col]]) |&gt; \n        purrr::map_dfr(function(measure) {\n            dt_measure &lt;- \n                dt |&gt; \n                dplyr::filter(.data[[measurement_col]] == measure)\n            \n            group_cols |&gt;\n                purrr::map_dfr(function(group_col) {\n                    dt_measure |&gt; \n                        dplyr::summarise(\n                            mean_value = mean(.data[[value_col]], na.rm = TRUE), \n                            .by = dplyr::all_of(group_col)\n                        ) |&gt; \n                        dplyr::summarise(\n                            AVAL = mean_value[1] / mean_value[2],\n                            group_value1 = .data[[group_col]][1], \n                            group_value2 = .data[[group_col]][2],\n                            group_column = group_col,\n                            !!measurement_col := measure\n                        ) |&gt; \n                        dplyr::collect()\n                })\n        }) |&gt; \n        dplyr::mutate(\n            PARAM = \"fold_change\"\n        ) |&gt; \n        dplyr::relocate(\n            dplyr::any_of(c(\n                \"group_column\",measurement_col,\n                \"group_value1\",\"group_value2\",\n                \"PARAM\",\"AVAL\"\n            ))\n        )\n    \n    return(result)\n}\n\n\ntm &lt;- \n    microbenchmark::microbenchmark(\n        compute_fc_dt(\n            create_dataset(n=1e3,n_tests = 1,n_groups = 10),\"name\",c(\"group\")\n        ),\n        compute_fc_dplyr(\n            create_dataset(n=1e3,n_tests = 1,n_groups = 10),\"name\",c(\"group\")\n        ),\n        compute_fc_dtplyr(\n            create_dataset(n=1e3,n_tests = 1,n_groups = 10),\"name\",c(\"group\")\n        ),\n        compute_fc_dplyr(\n            create_dataset(n=1e3,n_tests = 10,n_groups = 10),\"name\",c(\"group\")\n        ),\n        compute_fc_dtplyr(\n            create_dataset(n=1e3,n_tests = 10,n_groups = 10),\"name\",c(\"group\")\n        ),\n        compute_fc_dplyr(\n            create_dataset(n=1e3,n_tests = 100,n_groups = 10),\"name\",c(\"group\")\n        ),\n        compute_fc_dtplyr(\n            create_dataset(n=1e3,n_tests = 100,n_groups = 10),\"name\",c(\"group\")\n        ),\n        unit = \"second\",\n        times = 30\n    )\ntm |&gt; ggplot2::autoplot()"
  },
  {
    "objectID": "content/garden/projects/pds/pds-portal.html",
    "href": "content/garden/projects/pds/pds-portal.html",
    "title": "PDSportal",
    "section": "",
    "text": "Drug side effects in children were mined from openFDA, the publicly available repository of the FDA. This is the first resource of 460,837 adverse drug events (ADEs) with estimated risk across child development stages. This R shinydashboard application is the publicly accessible web application of this resource. See the publication for more details:\nGiangreco NP, Tatonetti NP. A database of pediatric drug effects to evaluate ontogenic mechanisms from child growth and development. Med (N Y). 2022 Jun 20:S2666-6340(22)00232-X. doi: 10.1016/j.medj.2022.06.001. Epub ahead of print. PMID: 35752163.\nThe PDSportal contains an Overview section with further instructions on how to use it. Feel free to play around!"
  },
  {
    "objectID": "content/garden/projects/pds/index.html",
    "href": "content/garden/projects/pds/index.html",
    "title": "Pediatric Drug Safety",
    "section": "",
    "text": "Drug safety in children can be affected by a number of dynamic variables such as enzymatic activity and hormonal levels that change during child growth and development. However, tools to predict adverse events in pediatric patients currently do not take into account these dynamics. My PhD advisor, Nicholas Tatonetti, and I developed a pharmacovigilance signal-detection algorithm to identify dynamic adverse events (such as metabolic and psychiatric disorders). We developed a database and a web application that provides the first resource to identify and evaluate drug safety signals across child-development stages. The cover symbolizes the data-driven method of the authors to provide more clarity on drug safety in pediatric patients, as parts of the image become better refined. Cover credit: adapted by Kip Lyall from FG Trade/E+ via Getty Images.\n\n\n\n\n\n\n\n\n\n\n\n\nKidSIDES\n\n\nAn R data package to access publically available pediatric drug safety information\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDSportal\n\n\nR shinydashboard application to access publicly available pediatric drug safety information\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/garden/projects/mccv/index.html",
    "href": "content/garden/projects/mccv/index.html",
    "title": "Monte Carlo Cross Validation",
    "section": "",
    "text": "Monte Carlo Cross Validation (MCCV) is a machine learning framework designed to estimate clinical outcomes and effects in patient cohorts to generate clinical and biological hypotheses. MCCV was used to in the following publications:\n\nGiangreco NP, Lebreton G, Restaino S, Jane Farr M, Zorn E, Colombo PC, Patel J, Levine R, Truby L, Soni RK, Leprince P, Kobashigawa J, Tatonetti NP, Fine BM. Plasma kallikrein predicts primary graft dysfunction after heart transplant. J Heart Lung Transplant. 2021 Jul 10:S1053-2498(21)02391-3. doi: 10.1016/j.healun.2021.07.001.\nGiangreco, N.P., Lebreton, G., Restaino, S. et al. Alterations in the kallikrein-kinin system predict death after heart transplant. Sci Rep 12, 14167 (2022). https://doi.org/10.1038/s41598-022-18573-2\n\nThe prediction scheme, Monte Carlo Cross Validation (MCCV), is composed of 5 steps repeated multiple times (e.g. N=200):\n\nSplit the data into 85% training and 15% validation sets.\nSeparately normalize, or subtract the sample mean and divide by the sample standard deviation, the training and testing data.\nUsing only the sampled training data, compute ten-fold cross validation and choose the top performing model parameters for predicting the response.\nRefit the training dataset using the top-prediction model parameters determined in step 3.\nPredict patient response in the yet-to-be-seen validation set using the refit model calculated in step 4.\n\nThe above publications resulted from my PhD work at Columbia University. In my free time after my PhD, I put together the python functions and scripts as a package for MCCV routines. Additionally, I am conducting a simulation experiment to evaluate outcome prediction for different biomarker distributions.\n\n\n\n\n\n\n\n\n\n\n\n\nMCCV (Shiny for Python) App\n\n\nA web application to simulate prior data distributions and inspective predictive evidence using MCCV\n\n\n\npython\n\n\nshiny\n\n\napp\n\n\nshiny-for-python\n\n\nprediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMCCV for Biomarker Prediction\n\n\nA simulation study to evaluate prediction of clinical outcomes and responses using biomarker data\n\n\n\npython\n\n\nbiomarker\n\n\ndistributions\n\n\nsimulation\n\n\nprediction\n\n\ndifferential expression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonte Carlo Cross Validation\n\n\nA python package for implementing MCCV\n\n\n\npython\n\n\npackage\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "content/garden/projects/mccv/mccv-package.html",
    "href": "content/garden/projects/mccv/mccv-package.html",
    "title": "Monte Carlo Cross Validation",
    "section": "",
    "text": "MCCV routines implemented within a python class. See the github for code, details, and issues."
  },
  {
    "objectID": "content/garden/index.html#welcome-to-my-digital-garden",
    "href": "content/garden/index.html#welcome-to-my-digital-garden",
    "title": "Nicholas Giangreco",
    "section": "🌳Welcome to my digital garden🌳",
    "text": "🌳Welcome to my digital garden🌳\nA digital garden is an online space for sharing and cultivating knowledge 🌈 It embodies the notion of working out loud 🤓\n\nProjects ➡️ Collection of code, notebooks, packages, and/or writings\nPosts ➡️ Announcements, standalone essay, or opinions\nDiscussion ➡️ Github issues"
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_CV.html",
    "href": "content/cv/Nicholas_Giangreco_CV.html",
    "title": "Nick Giangreco",
    "section": "",
    "text": "Github: ngiangre | Linkedin: http://www.linkedin.com/in/nickgiangreco/ | ORCID: 0000-0001-8138-4947 | Personal Website: nickg.bio | Email: nick.giangreco@gmail.com | Date of preparation: January 11th 2025\n\n\n\nTopic expertise: Bioinformatics, Biomarker evaluation and discovery, Applications engineering, Scientific data modeling and architecture, Pediatric drug safety, Interpretable machine learning and AI, fairness and equity in biomedical informatics\n\n\nTechnical expertise: biomedical data science, (R/Python) software package development, R programming, {plumber} APIs, machine learning, statistical simulation, data cleaning, data pipelines, Shiny (for R and Python) application development, object oriented programming, RMarkdown/JuPyteR/Quarto, Microsoft Power App and API user\n\n\nProgramming Languages: R, Python, SQL, HTML, CSS, Java, bash\n\n\nPatents: Systems and methods for predicting graft dysfunction with exosome proteins"
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_CV.html#work-experience",
    "href": "content/cv/Nicholas_Giangreco_CV.html#work-experience",
    "title": "Nick Giangreco",
    "section": "WORK EXPERIENCE",
    "text": "WORK EXPERIENCE\n\nFebruary 2023 - Present\n\nComputer Sciences Advisor (Remote) (MindArch Health); Sayville, NY\nMachine learning, Software, Web Applications & Design\n\nDecember 2021 - Present\n\nSenior Scientist, Quantitative Translational Science (Remote) (Regeneron Pharmaceuticals Inc.); Tarrytown, NY\nPrecision Medicine - scientist, data architect, software developer, and applications engineer\n\nAnalyze clinical and biomarker data in rare disease and drug trials\nManage execution of data architecture and software development projects in precision medicine innovation development portfolio.\nDevelop and maintain 6+ software packages and data pipelines for team of clinical biomarker data analysts.\nDeliver automated project management and portfolio reports to senior leadership.\nMentor interns and data scientists to develop reproducible data analyses and web apps.\n\n\nAugust 2016 - October 2021\n\nSystems biologist (Columbia University); New York, NY\nPh.D. Thesis: Mind the developmental gap: Identifying adverse drug effects across childhood to evaluate biological mechanisms from growth and development\nCell Press cover art\nPDSportal Shiny for R application\nkidsides R package and database\nColumbia University media release\n\nFebruary 2021 - August 2021\n\nBioinformatics intern (DNAnexus); San Francisco, CA\nSolutions Science team\nInitiated internal and external projects such as interpretable, tree-based andd boosting machine learning for phenotype prediction and 2) integration of genomic/phenomic data using common data models\n\nJune 2019 - August 2019\n\nClinical informatics intern (Regeneron Genetics Center)); Tarrytown, NY\nDeveloped database of multivariate clinical associations using incremental learning technique on EC2 Amazon Web Services.\n\nJuly 2018 - September 2018\n\nComputational biology intern (Genetic Leap); New York, NY\nFormerly Genetic Intelligence Inc.\nConducted independent and collaborative genomics research using NCBI APIs and Amazon Web Services.\n\nAugust 2014 - July 2019\n\nCancer bioinformatician (National Human Genome Research Institute); Bethesda, MD\nPost-baccalaureate trainee 2014-2016; Special volunteer 2016-2019\nInvestigated ovarian endometrioid tumorigenesis by integrating and analyzing RNA-Seq and DNA methylation sequencing (MBD-Seq)."
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_CV.html#education",
    "href": "content/cv/Nicholas_Giangreco_CV.html#education",
    "title": "Nick Giangreco",
    "section": "EDUCATION",
    "text": "EDUCATION\n\n2016 - 2021\n\nPhD, Systems Biology; Columbia University, New York City, NY\nPhD advisor: Dr. Nicholas Tatonetti\nMasters of Arts (2018) and Masters of Philosophy (2019)\n\n2010 - 2014\n\nBS, Biochemistry; University of Rochester, Rochester, NY"
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_CV.html#select-publications",
    "href": "content/cv/Nicholas_Giangreco_CV.html#select-publications",
    "title": "Nick Giangreco",
    "section": "SELECT PUBLICATIONS",
    "text": "SELECT PUBLICATIONS\n\nBiswas S, Shahriar S, Giangreco NP, Arvanitis P, Winkler M, Tatonetti NP, Brunken WJ, Cutforth T, Agalliu D. Mural Wnt/β-catenin signaling regulates Lama2 expression to promote neurovascular unit maturation. Development. 2022 Sep 1;149(17):dev200610. doi: 10.1242/dev.200610. Epub 2022 Sep 13. PMID: 36098369; PMCID: PMC9578690.\nGiangreco, N.P., Lebreton, G., Restaino, S. et al. Alterations in the kallikrein-kinin system predict death after heart transplant. Sci Rep 12, 14167 (2022). https://doi.org/10.1038/s41598-022-18573-2\nGiangreco NP, Tatonetti NP. A database of pediatric drug effects to evaluate ontogenic mechanisms from child growth and development. Med (N Y). 2022 Aug 12;3(8):579-595.e7. doi: 10.1016/j.medj.2022.06.001. Epub 2022 Jun 24. PMID: 35752163; PMCID: PMC9378670.\nGiangreco, Nicholas (2022), Longitudinal trends of EHR concepts in pediatric patients, Dryad, Dataset, https://doi.org/10.5061/dryad.j0zpc86g3\nNicholas P Giangreco, Sulieman Lina, Jun Qian, Aymone Kuoame, Vignesh Subbian, Eric Boerwinkle, Mine Cicek, Cheryl R Clark, Elizabeth Cohen, Kelly A Gebo, Roxana Loperena-Cortes, Kelsey Mayo, Stephen Mockrin, Lucila Ohno-Machado, Sheri D Schully, Nicholas P Tatonetti, Andrea H Ramirez, Pediatric data from the All of Us research program: demonstration of pediatric obesity over time, JAMIA Open, Volume 4, Issue 4, October 2021, ooab112, https://doi.org/10.1093/jamiaopen/ooab112\nGiangreco NP, Lebreton G, Restaino S, Jane Farr M, Zorn E, Colombo PC, Patel J, Levine R, Truby L, Soni RK, Leprince P, Kobashigawa J, Tatonetti NP, Fine BM. Plasma kallikrein predicts primary graft dysfunction after heart transplant. J Heart Lung Transplant. 2021 Jul 10:S1053-2498(21)02391-3. doi: 10.1016/j.healun.2021.07.001.\nGiangreco, N.P., Tatonetti, N.P. Evaluating risk detection methods to uncover ontogenic-mediated adverse drug effect mechanisms in children. BioData Mining 14, 34 (2021). https://doi.org/10.1186/s13040-021-00264-9.\nGiangreco, NP, Elias, JE, Tatonetti, NP. No population left behind: Improving paediatric drug safety using informatics and systems biology. Br J Clin Pharmacol. 2021; 1– 7. https://doi.org/10.1111/bcp.14705.\nNicholas P. Giangreco, Barry Fine, Nicholas P. Tatonetti. cohorts: A Python package for clinical ’omics data management. bioaRxiv doi: https://www.biorxiv.org/content/10.1101/626051\nBenjamin S Glicksberg, Boris Oskotsky, Phyllis M Thangaraj, Nicholas Giangreco, Marcus A Badgeley, Kipp W Johnson, Debajyoti Datta, Vivek A Rudrapatna, Nadav Rappoport, Mark M Shervey, Riccardo Miotto, Theodore C Goldstein, Eugenia Rutenberg, Remi Frazier, Nelson Lee, Sharat Israni, Rick Larsen, Bethany Percha, Li Li, Joel T Dudley, Nicholas P Tatonetti, Atul J Butte, PatientExploreR: an extensible application for dynamic visualization of patient clinical history from electronic health records in the OMOP common data model, Bioinformatics, Volume 35, Issue 21, 1 November 2019, Pages 4515–4518, https://doi.org/10.1093/bioinformatics/btz409.\nBenjamin S Glicksberg, Boris Oskotsky, Nicholas Giangreco, Phyllis M Thangaraj, Vivek Rudrapatna, Debajyoti Datta, Remi Frazier, Nelson Lee, Rick Larsen, Nicholas P Tatonetti, Atul J Butte, ROMOP: a light-weight R package for interfacing with OMOP-formatted electronic health record data, JAMIA Open, Volume 2, Issue 1, April 2019, Pages 10–14, https://doi.org/10.1093/jamiaopen/ooy059\nEstibaliz Castillero, Ziad A. Ali, Hirokazu Akashi, Nicholas Giangreco, Catherine Wang, Eric J. Stöhr, Ruping Ji, Xiaokan Zhang, Nathaniel Kheysin, Joo-Eun S. Park, Sheetal Hegde, Sanatkumar Patel, Samantha Stein, Carlos Cuenca, Diana Leung, Shunichi Homma, Nicholas P. Tatonetti, Veli K. Topkara, Koji Takeda, Paolo C. Colombo, Yoshifumi Naka, H. Lee Sweeney, P. Christian Schulze, and Isaac George American Journal of Physiology-Heart and Circulatory Physiology 2018 315:5, H1463-H1476.\nKim-Hellmuth, S., Bechheim, M., Pütz, B., Mohammadi, P., Néd´lec, Y, Giangreco, N., et al. Genetic regulatory effects modified by immune activation contribute to autoimmune disease associations. Nat Commun 8, 266 (2017). https://doi.org/10.1038/s41467-017-00366-1.\n\nPeer-reviewed publications on pubmed\nGoogle scholar profile"
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_CV.html#fellowships-and-awards",
    "href": "content/cv/Nicholas_Giangreco_CV.html#fellowships-and-awards",
    "title": "Nick Giangreco",
    "section": "FELLOWSHIPS AND AWARDS",
    "text": "FELLOWSHIPS AND AWARDS\n\nTravel award to present on a panel at the 2022 American Medical Informatics Association Summit in Chicago, USA\nTravel award to 2021 Elixir biohackathon in Barcelona Spain.\nSpecial recognition from Columbia University for service during the COVID-19 crisis, 2021\n2021 Diversity & Inclusion Commercialization and Entrepreneurship Fellow @ Columbia Technology Ventures\nThree-Minute Thesis 2019 finalist @ Columbia Graduate School of Arts and Sciences.\nBest contribution in methodological research at the OHDSI 2018 Symposium for Pediatric Drug Safety poster.\nColumbia Diversity Fellowship 2016.\nDepartment of Systems Biology Merit Fellowship 2016.\nDonald Charles Award, University of Rochester Department of Biology, 2014.\nFulbright Fellowship Alternate 2013-2014: Sweden, Molecular Modeling, “Novel Antibody-SpA Complex Modeling”.\nTravel Award to 9th Student Council and ISMB/ECCB conference 2013 Berlin, Germany."
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_CV.html#posters-and-software",
    "href": "content/cv/Nicholas_Giangreco_CV.html#posters-and-software",
    "title": "Nick Giangreco",
    "section": "POSTERS AND SOFTWARE",
    "text": "POSTERS AND SOFTWARE\n\nNicholas Giangreco, Salvatore G. Volpe, Meghana Tandon, Kamileh Narisnh, Ben Busby. All Genes Lead to ROMOPOmics. OHDSI symposium video demo\nNick Giangreco and Nicholas Tatonetti. Using precision pharmacovigilance to detect developmentally-regulated adverse drug reactions: a case study with antiepileptic drugs. poster github\nNick Giangreco and Nicholas Tatonetti. Using precision pharmacovigilance to detect and evaluate antiepileptic drug associated adverse reactions in pediatric patients. poster\nNick Giangreco and Nicholas Tatonetti. cohorts. github\nNick Giangreco. Scan2CNV. OMICSTools\nGiangreco N, Zorn E, Chen E et al. Identification of novel primary graft dysfunction biomarkers using exosome proteomics [version 1; not peer reviewed]. F1000Research 2017, 6:2080 (poster) (doi: 10.7490/f1000research.1115115.1)\nGiangreco N and Lezon T. Alternative conformation prediction of Vibrio Cholerae concentrative nucleoside transporter. F1000Posters 2013, 4:776 (poster)."
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_CV.html#leadership-and-management-experience",
    "href": "content/cv/Nicholas_Giangreco_CV.html#leadership-and-management-experience",
    "title": "Nick Giangreco",
    "section": "Leadership and Management Experience",
    "text": "Leadership and Management Experience\n\nUniversity of Rochester Alumni Buffalo Leadership Council 2023-Present\n\nIdeate and organize local events\n\nNew York Health Artificial Intelligence Society 2019-2024\n\n501(c)(3) not-for-profit Cofounder and Secretary, 2019-2024\nPromote public discourse on a wide range of topics such as AI & Society, AI & Healthcare, and economic impact by AI.\nOrganize and facilitate group engagement, workshops, AI study groups, and not-for-profit organization.\nConsultant on data science and education projects and initiatives.\n\nUniversity of Rochester Alumni Undergraduate Interviewer 2016-2022\n\nAssess potential and suitability for undergraduate college\nInterviewer at large and small event settings\n\nCUIMC Department of Biomedical Informatics Justice Informatics Reading group\n\nMember January 2021-December 2021\nRead and discuss publications, books, and policy on fairness and ethics within informatics development and their application\n\nCUIMC Data Science Club\n\nPresident 2017-2021\nOrganize and manage team of officers, oversee activities, manage budget, and promote outreach portfolio to support and strengthen the data science skills of biomedical scientists at CUIMC\n\nHealth Tech Assembly\n\nPresident 2019-2020\n\nManage business, medical, public health, and engineering representatives for inter-school events, panels, and conferences at Columbia.\nOrganize and plan professional/social engagement events.\nNetwork and connect with NYC-wide entrepreneurs and professionals.\n\nMedical campus representative 2018-2019\n\nGraduate Student Organization at Columbia University Irving Medical Center\n\nCo-President 2019-2020\n\nOrganize and manage team of Biomedical PhDs for social and professional activities serving hundreds of CUIMC PhD students.\n\nFinance Chair 2018-2019\n\nColumbia Graduate Council\n\nTreasurer 2019-2020\n\nEstablish budget and expense sheets and annual reports\nManage forty thousand dollar budget for Columbia inter-school activities.\n\n\nDepartment of Biomedical Informatics\n\nCo-lead weekly seminar series\nManage presentation schedule, speaker logistics and travel, and promote team coordination.\n\nDepartment of Systems Biology\n\nPoint person for Systems Biology Trainee Council\nSecured funding and launched event portfolio for trainee development\nManage monthly departmental happy hours"
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_CV.html#mentoring-tutoring-and-writing",
    "href": "content/cv/Nicholas_Giangreco_CV.html#mentoring-tutoring-and-writing",
    "title": "Nick Giangreco",
    "section": "MENTORING, TUTORING, and WRITING",
    "text": "MENTORING, TUTORING, and WRITING\n\nMentor in the Say Yes not-for-profit in Buffalo NY\n\nMission is to remove barriers to educational and economic attainment for our young people.\n\nMentor in technical and entrepreneurship development for the Innovate Children’s Health Challenge\nAdvisor, mentor and tutor for project management, R and python programming, and statistics and machine learning to high school/college/graduate students and professionals.\n“Hack nights – Solving healthcare data-science/AI/ML problems” Introduction to cancer genomics four part series. Co-led with Matthew Eng\n\nAdventures In Hacking Healthcare Medium Publication\n\nNicholas Giangreco. “The Importance of being Open”. PHDISH January 9th 2019.\nMentoring:\n\nPayal Chandak, Undergraduate at Columbia University\n\nProvide guidance and instruction in biomedical data science and research training.\nProvided guidance and mentoring for summer 2018 research internship in the Tatonetti Lab\n\n“Drugs with sex-linked risk for adverse drug reactions”\n\n\nSMRI high school mentorship\n\nProvide guidance to high school student in biomedical data science research project\n\n\nCuriology tutor\n\nManaged and co-led science experiments with NIH fellows for middle school students in Washington D.C.\n\nCollege Bound tutor\n\nFacilitated completion of homework assignments in STEM for Washington D.C. high school students.\n\nGenetics Study Group Leader, Center for Excellence in Teaching and Learning, University of Rochester."
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_CV.html#conferences-and-hackathons",
    "href": "content/cv/Nicholas_Giangreco_CV.html#conferences-and-hackathons",
    "title": "Nick Giangreco",
    "section": "CONFERENCES AND HACKATHONS",
    "text": "CONFERENCES AND HACKATHONS\n\nposit::conf( c(2023,2024) ) with workshops\nBio-IT World 2023\nrstudio::conf(2022)\nAmerican Medical Informatics Association Translational Summit 2022 Chicago USA\n2021 Elixir biohackathon\n\nFront-end developer\nBuilt prototype dashboard for improved disease subtyping and treatment pathways for colorectal cancer. See github and shiny dashboard.\n\nClinical Reporting of Multi ’Omics data\n\nLed team and managed hackathon teams to manage and streamline integration of genomic, transcriptomic, and polygenic risk score data into the OMOP common data model. See github.\n\nElixir biohackathon\n\nCollaborated with bioinformatics team to integrate nextflow scheme and cancer mutation data (vcf files) into OMOP standard structure using ROMOPOmics.\n\nHack for NF, Children’s Tumor Foundation\n\nCo-lead web developer coordination and product development\nA FHIR-complient and primarily patient-centric profile for NF management and centralized repository for medical journey.\n\nJudge, Predictive analytics track, Columbia University COVID-19 Data Challenge\nVirtual Interoperathon 2020\n\nProject developer for personalized health record accessed with fhir-client python api\nDeveloped flask application proof-of-concept.\n\nNCBI Hackathon @ Carnegie Mellon University January 2020\n\nProject co-lead for developing and extending common data model to represent biological ’omics data for reproducible queries and analyses.\nSee original OMOPOmics and R package ROMOPOmics github repository.\n\nCSHL Biological Data Science meeting November 2018.\nOHDSI 2018 Symposium\nNCBI Hackathon @ New York Genome Center August 2018\n\nProject lead for developing data science notebooks and web application interfacing with drug safety data.\nSee SafeDrugs github repository.\n\nIntelligent Systems in Molecular Biology, July 2018\nSecond Northeast Computational Health Summit, April 2018\nAmerican Heart Association Scientific Sessions 2017, poster presentation Giangreco et al. 2017.\nNCBI Hackathon @ New York Genome Center June 2017.\nNCBI Hackathon @ NCBI March 2017.\nCSHL Biological Data Science meeting October 2016.\nJHU DaSH Hackathon September 2015.\nISMB/ECCB conference @ Berlin, Germany July 2013, poster presentation Giangreco et al. 2013."
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_CV.html#talks-and-panels",
    "href": "content/cv/Nicholas_Giangreco_CV.html#talks-and-panels",
    "title": "Nick Giangreco",
    "section": "TALKS AND PANELS",
    "text": "TALKS AND PANELS\n\nPanelist for S14: “Utility of the All of Us Researcher Workbench in Educational and Research Settings” American Medical Informatics Association Informatics Summit March 2022 Chicago.\nDBMI Justice Informatics Joint Forum. Internal, collaborative meeting discussing the impact of Big Data and mathematical models on inequity and how that applies to research.\n“Pediatrics data in All of Us”. All of Us Research Workbench Onramp Virtual Event June 2021.\n2021 Graduate Scholar for research talk entitled ‘Mind the developmental gap: Identifying adverse drug effects across childhood to evaluate biological mechanisms from growth and development’ with Emuritus Professors at Columbia (EPIC)\n“Understanding dynamics with statistical modeling” Coding workshop, CUIMC Data Science Club, YouTube video\n“Introduction to programming and bioinformatics” Tutorial for 2021 Columbia University Science Matters Research Internship\n“Intro to Bioinformatics and How to Analyze Brain Tissue with Data Science”. Invited presentation at NYC Medical Research and Bioinformatics Group. November 2018. Presentation link.\nMedical Research Career Panelist, Minds Matter NYC, June 2018\nStandardized and Reproducible Analysis Enables Identification of Novel Primary Graft Dysfunction Biomarkers using Exosome Proteomics, Second NorthEast Computational Health Summit 2018, April 2018.\n“Tools, Libraries and Analyses in Biomedical Data Science”, New York Healthcare Artificial Intelligence Society, December 2017.\n“Doing Science with Big Data”, Late Night Science, Columbia University Neuroscience Outreach, December 2017.\n“AI, Life Sciences, and Big Data”, New York Healthcare Artificial Intelligence Society, August 2017. Presentation link.\nNIDDK Undergraduate Step-Up Judge, NIH, Bethesda MD, August 2015."
  },
  {
    "objectID": "content/cv/Nicholas_Giangreco_CV.html#professional-memberships",
    "href": "content/cv/Nicholas_Giangreco_CV.html#professional-memberships",
    "title": "Nick Giangreco",
    "section": "PROFESSIONAL MEMBERSHIPS",
    "text": "PROFESSIONAL MEMBERSHIPS\n\nInternational Society of Computational Biology, 2013-2014 & 2017-2018\nAmerican Heart Association, 2017-2018.\nAmerican Medical Informatics Association, 2017-2018."
  },
  {
    "objectID": "content/cv/Biosketch/Nick_Giangreco_NIHBioSketch.html",
    "href": "content/cv/Biosketch/Nick_Giangreco_NIHBioSketch.html",
    "title": "Personal Statement",
    "section": "",
    "text": "I have led and contributed to precision medicine research as a PhD trainee and currently in the pharmaceutical industry. My PhD thesis work led to multiple publications including a database of pediatric-specific adverse drug effect signals aligning with dynamic physiological processes during child development. I led the data science efforts to develop an interpretable and robust machine learning algorithm that led to hypothesized biological mechanism for a fatal, idiopathic graft dysfunction after heart transplant surgery."
  },
  {
    "objectID": "content/cv/Biosketch/Nick_Giangreco_NIHBioSketch.html#positions-and-employment",
    "href": "content/cv/Biosketch/Nick_Giangreco_NIHBioSketch.html#positions-and-employment",
    "title": "Personal Statement",
    "section": "Positions and Employment",
    "text": "Positions and Employment"
  },
  {
    "objectID": "content/cv/Biosketch/Nick_Giangreco_NIHBioSketch.html#other-experience-and-professional-memberships",
    "href": "content/cv/Biosketch/Nick_Giangreco_NIHBioSketch.html#other-experience-and-professional-memberships",
    "title": "Personal Statement",
    "section": "Other Experience and Professional Memberships",
    "text": "Other Experience and Professional Memberships"
  },
  {
    "objectID": "content/cv/Biosketch/Nick_Giangreco_NIHBioSketch.html#honors",
    "href": "content/cv/Biosketch/Nick_Giangreco_NIHBioSketch.html#honors",
    "title": "Personal Statement",
    "section": "Honors",
    "text": "Honors"
  }
]